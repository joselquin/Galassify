{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galassify v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de librerías y carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T19:09:55.320690Z",
     "start_time": "2019-11-03T19:09:55.296696Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import galassify_autoencoder as autoencoder\n",
    "import galassify_grafica_error, galassify_grafOutlier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans, DBSCAN \n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, cargamos directamente los datasets original y el dataset sin negativos, creados en notebooks anteriores. Hay que tener en cuenta que el dataset sin negativos tiene algunos espectros menos que el original y que, por tanto, los índices varían."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T19:10:01.006913Z",
     "start_time": "2019-11-03T19:09:58.848767Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLATE</th>\n",
       "      <th>MJD</th>\n",
       "      <th>FIBER</th>\n",
       "      <th>Z</th>\n",
       "      <th>3868.645565753641</th>\n",
       "      <th>3869.535542582065</th>\n",
       "      <th>3870.4278489317717</th>\n",
       "      <th>3871.318235772099</th>\n",
       "      <th>3872.2109532069176</th>\n",
       "      <th>3873.1017502480395</th>\n",
       "      <th>3873.992752215851</th>\n",
       "      <th>3874.8860863882537</th>\n",
       "      <th>3875.777498840249</th>\n",
       "      <th>3876.671244571283</th>\n",
       "      <th>3877.563067696571</th>\n",
       "      <th>3878.45722517584</th>\n",
       "      <th>3879.3494591636186</th>\n",
       "      <th>3880.2440285808143</th>\n",
       "      <th>3881.136673620369</th>\n",
       "      <th>3882.029524011743</th>\n",
       "      <th>3882.924711445972</th>\n",
       "      <th>3883.8179731730975</th>\n",
       "      <th>3884.713573019754</th>\n",
       "      <th>3885.6072462721336</th>\n",
       "      <th>3886.503258721214</th>\n",
       "      <th>3887.3973436884376</th>\n",
       "      <th>3888.291634338733</th>\n",
       "      <th>3889.188265801773</th>\n",
       "      <th>3890.082968451347</th>\n",
       "      <th>3890.980012992077</th>\n",
       "      <th>3891.8751278307373</th>\n",
       "      <th>3892.772585639461</th>\n",
       "      <th>3893.668112857104</th>\n",
       "      <th>3894.5638460896052</th>\n",
       "      <th>3895.461923910823</th>\n",
       "      <th>3896.3580698071996</th>\n",
       "      <th>3897.2565613724432</th>\n",
       "      <th>3898.15312012281</th>\n",
       "      <th>3899.052025622691</th>\n",
       "      <th>3899.9489974172493</th>\n",
       "      <th>3900.8461755589897</th>\n",
       "      <th>3901.745702071507</th>\n",
       "      <th>3902.643293542793</th>\n",
       "      <th>3903.543234466747</th>\n",
       "      <th>3904.4412394579995</th>\n",
       "      <th>3905.3415949843097</th>\n",
       "      <th>3906.2400136860347</th>\n",
       "      <th>3907.1386390678003</th>\n",
       "      <th>3908.039616608505</th>\n",
       "      <th>3908.9386559865584</th>\n",
       "      <th>...</th>\n",
       "      <th>7417.524757252301</th>\n",
       "      <th>7419.2311490749735</th>\n",
       "      <th>7420.942007391534</th>\n",
       "      <th>7422.649185348109</th>\n",
       "      <th>7424.356756038729</th>\n",
       "      <th>7426.068796308937</th>\n",
       "      <th>7427.777153676565</th>\n",
       "      <th>7429.489982682914</th>\n",
       "      <th>7431.199127089972</th>\n",
       "      <th>7432.91274519583</th>\n",
       "      <th>7434.622677004906</th>\n",
       "      <th>7436.333002181546</th>\n",
       "      <th>7438.047804147664</th>\n",
       "      <th>7439.758917270303</th>\n",
       "      <th>7441.474509244873</th>\n",
       "      <th>7443.186410676516</th>\n",
       "      <th>7444.902793023495</th>\n",
       "      <th>7446.615483127316</th>\n",
       "      <th>7448.328567233246</th>\n",
       "      <th>7450.0461353501705</th>\n",
       "      <th>7451.760008673134</th>\n",
       "      <th>7453.478368072875</th>\n",
       "      <th>7455.1930309764675</th>\n",
       "      <th>7456.9121820235705</th>\n",
       "      <th>7458.627634871548</th>\n",
       "      <th>7460.3434823572</th>\n",
       "      <th>7462.063821087017</th>\n",
       "      <th>7463.78045906279</th>\n",
       "      <th>7465.501590351842</th>\n",
       "      <th>7467.219019181919</th>\n",
       "      <th>7468.940943395341</th>\n",
       "      <th>7470.659163444065</th>\n",
       "      <th>7472.377778767054</th>\n",
       "      <th>7474.100892579042</th>\n",
       "      <th>7475.820299667295</th>\n",
       "      <th>7477.544207317</th>\n",
       "      <th>7479.264406535282</th>\n",
       "      <th>7480.989108388424</th>\n",
       "      <th>7482.710100101674</th>\n",
       "      <th>7484.431487726802</th>\n",
       "      <th>7486.157381097453</th>\n",
       "      <th>7487.879561765048</th>\n",
       "      <th>7489.606250253956</th>\n",
       "      <th>7491.329224329366</th>\n",
       "      <th>7493.0567083028445</th>\n",
       "      <th>7494.7804761515945</th>\n",
       "      <th>7496.504640550872</th>\n",
       "      <th>7498.233317963899</th>\n",
       "      <th>7499.958276684899</th>\n",
       "      <th>7501.6877504987915</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2099</td>\n",
       "      <td>53469</td>\n",
       "      <td>148</td>\n",
       "      <td>0.077807</td>\n",
       "      <td>0.636552</td>\n",
       "      <td>0.367806</td>\n",
       "      <td>0.278396</td>\n",
       "      <td>0.285307</td>\n",
       "      <td>0.183786</td>\n",
       "      <td>0.328635</td>\n",
       "      <td>0.450617</td>\n",
       "      <td>0.433929</td>\n",
       "      <td>0.899009</td>\n",
       "      <td>0.643836</td>\n",
       "      <td>0.475315</td>\n",
       "      <td>0.438675</td>\n",
       "      <td>0.467904</td>\n",
       "      <td>0.417998</td>\n",
       "      <td>0.323266</td>\n",
       "      <td>0.554133</td>\n",
       "      <td>0.877506</td>\n",
       "      <td>0.547206</td>\n",
       "      <td>0.296718</td>\n",
       "      <td>0.674742</td>\n",
       "      <td>0.606375</td>\n",
       "      <td>0.222630</td>\n",
       "      <td>0.451282</td>\n",
       "      <td>0.314469</td>\n",
       "      <td>0.190128</td>\n",
       "      <td>0.553508</td>\n",
       "      <td>0.495501</td>\n",
       "      <td>0.428374</td>\n",
       "      <td>1.490322</td>\n",
       "      <td>0.988478</td>\n",
       "      <td>0.554287</td>\n",
       "      <td>0.655043</td>\n",
       "      <td>0.784162</td>\n",
       "      <td>0.499813</td>\n",
       "      <td>0.408123</td>\n",
       "      <td>0.484755</td>\n",
       "      <td>0.473120</td>\n",
       "      <td>0.623950</td>\n",
       "      <td>0.716056</td>\n",
       "      <td>0.306379</td>\n",
       "      <td>0.408779</td>\n",
       "      <td>0.382334</td>\n",
       "      <td>0.384830</td>\n",
       "      <td>0.556806</td>\n",
       "      <td>0.535645</td>\n",
       "      <td>0.374631</td>\n",
       "      <td>...</td>\n",
       "      <td>1.403149</td>\n",
       "      <td>1.300737</td>\n",
       "      <td>0.854908</td>\n",
       "      <td>1.036072</td>\n",
       "      <td>1.284790</td>\n",
       "      <td>1.174821</td>\n",
       "      <td>1.219686</td>\n",
       "      <td>1.320632</td>\n",
       "      <td>1.182485</td>\n",
       "      <td>1.149967</td>\n",
       "      <td>1.135212</td>\n",
       "      <td>1.197466</td>\n",
       "      <td>1.170419</td>\n",
       "      <td>1.177966</td>\n",
       "      <td>1.258235</td>\n",
       "      <td>1.338014</td>\n",
       "      <td>0.992609</td>\n",
       "      <td>1.281974</td>\n",
       "      <td>1.229110</td>\n",
       "      <td>1.421697</td>\n",
       "      <td>1.077822</td>\n",
       "      <td>1.240584</td>\n",
       "      <td>1.259480</td>\n",
       "      <td>1.368396</td>\n",
       "      <td>0.990141</td>\n",
       "      <td>1.229603</td>\n",
       "      <td>1.239413</td>\n",
       "      <td>1.142440</td>\n",
       "      <td>1.154854</td>\n",
       "      <td>1.272670</td>\n",
       "      <td>1.196519</td>\n",
       "      <td>1.218197</td>\n",
       "      <td>1.355392</td>\n",
       "      <td>1.242389</td>\n",
       "      <td>1.247098</td>\n",
       "      <td>1.202379</td>\n",
       "      <td>0.861311</td>\n",
       "      <td>1.392254</td>\n",
       "      <td>1.273615</td>\n",
       "      <td>1.089576</td>\n",
       "      <td>1.155214</td>\n",
       "      <td>1.211078</td>\n",
       "      <td>1.142575</td>\n",
       "      <td>1.233846</td>\n",
       "      <td>1.084954</td>\n",
       "      <td>1.169770</td>\n",
       "      <td>1.161821</td>\n",
       "      <td>1.160405</td>\n",
       "      <td>1.275585</td>\n",
       "      <td>1.238802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1815</td>\n",
       "      <td>53884</td>\n",
       "      <td>1</td>\n",
       "      <td>0.091045</td>\n",
       "      <td>0.924821</td>\n",
       "      <td>0.955832</td>\n",
       "      <td>0.954143</td>\n",
       "      <td>0.935017</td>\n",
       "      <td>0.832751</td>\n",
       "      <td>0.854249</td>\n",
       "      <td>0.846123</td>\n",
       "      <td>0.740990</td>\n",
       "      <td>0.776660</td>\n",
       "      <td>0.833628</td>\n",
       "      <td>0.880842</td>\n",
       "      <td>0.866295</td>\n",
       "      <td>0.799464</td>\n",
       "      <td>0.879522</td>\n",
       "      <td>0.877655</td>\n",
       "      <td>0.809836</td>\n",
       "      <td>0.658508</td>\n",
       "      <td>0.459713</td>\n",
       "      <td>0.461437</td>\n",
       "      <td>0.597803</td>\n",
       "      <td>0.624169</td>\n",
       "      <td>0.539646</td>\n",
       "      <td>0.642504</td>\n",
       "      <td>0.783469</td>\n",
       "      <td>0.816040</td>\n",
       "      <td>0.770628</td>\n",
       "      <td>0.738639</td>\n",
       "      <td>0.680130</td>\n",
       "      <td>0.671148</td>\n",
       "      <td>0.666353</td>\n",
       "      <td>0.646091</td>\n",
       "      <td>0.744776</td>\n",
       "      <td>0.752563</td>\n",
       "      <td>0.641500</td>\n",
       "      <td>0.638825</td>\n",
       "      <td>0.777697</td>\n",
       "      <td>0.875334</td>\n",
       "      <td>0.836110</td>\n",
       "      <td>0.780308</td>\n",
       "      <td>0.769351</td>\n",
       "      <td>0.740468</td>\n",
       "      <td>0.693389</td>\n",
       "      <td>0.687770</td>\n",
       "      <td>0.675530</td>\n",
       "      <td>0.765399</td>\n",
       "      <td>0.892660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779851</td>\n",
       "      <td>0.728282</td>\n",
       "      <td>0.705656</td>\n",
       "      <td>0.796199</td>\n",
       "      <td>0.861313</td>\n",
       "      <td>0.789964</td>\n",
       "      <td>0.813254</td>\n",
       "      <td>0.877838</td>\n",
       "      <td>0.832707</td>\n",
       "      <td>0.821114</td>\n",
       "      <td>0.850069</td>\n",
       "      <td>0.809483</td>\n",
       "      <td>0.786298</td>\n",
       "      <td>0.802253</td>\n",
       "      <td>0.844928</td>\n",
       "      <td>0.827333</td>\n",
       "      <td>0.783233</td>\n",
       "      <td>0.829814</td>\n",
       "      <td>0.783733</td>\n",
       "      <td>0.794661</td>\n",
       "      <td>0.810325</td>\n",
       "      <td>0.747440</td>\n",
       "      <td>0.753007</td>\n",
       "      <td>0.828389</td>\n",
       "      <td>0.864708</td>\n",
       "      <td>0.812884</td>\n",
       "      <td>0.745643</td>\n",
       "      <td>0.751192</td>\n",
       "      <td>0.838403</td>\n",
       "      <td>0.857025</td>\n",
       "      <td>0.785440</td>\n",
       "      <td>0.767616</td>\n",
       "      <td>0.743195</td>\n",
       "      <td>0.724839</td>\n",
       "      <td>0.805945</td>\n",
       "      <td>0.840591</td>\n",
       "      <td>0.810032</td>\n",
       "      <td>0.829138</td>\n",
       "      <td>0.850290</td>\n",
       "      <td>0.763131</td>\n",
       "      <td>0.688105</td>\n",
       "      <td>0.779044</td>\n",
       "      <td>0.817667</td>\n",
       "      <td>0.815495</td>\n",
       "      <td>0.831063</td>\n",
       "      <td>0.807701</td>\n",
       "      <td>0.825111</td>\n",
       "      <td>0.779291</td>\n",
       "      <td>0.775595</td>\n",
       "      <td>0.852922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>699</td>\n",
       "      <td>52202</td>\n",
       "      <td>92</td>\n",
       "      <td>0.043789</td>\n",
       "      <td>1.258258</td>\n",
       "      <td>1.268783</td>\n",
       "      <td>1.352357</td>\n",
       "      <td>1.341881</td>\n",
       "      <td>1.336860</td>\n",
       "      <td>1.250001</td>\n",
       "      <td>0.957059</td>\n",
       "      <td>0.828157</td>\n",
       "      <td>1.033551</td>\n",
       "      <td>1.245475</td>\n",
       "      <td>1.137744</td>\n",
       "      <td>0.829527</td>\n",
       "      <td>0.732822</td>\n",
       "      <td>0.620484</td>\n",
       "      <td>0.690629</td>\n",
       "      <td>0.910615</td>\n",
       "      <td>0.772459</td>\n",
       "      <td>0.725904</td>\n",
       "      <td>0.839652</td>\n",
       "      <td>0.876705</td>\n",
       "      <td>0.870031</td>\n",
       "      <td>0.748934</td>\n",
       "      <td>0.776170</td>\n",
       "      <td>0.772296</td>\n",
       "      <td>0.753819</td>\n",
       "      <td>0.862681</td>\n",
       "      <td>0.692442</td>\n",
       "      <td>0.552839</td>\n",
       "      <td>0.605622</td>\n",
       "      <td>0.583866</td>\n",
       "      <td>0.573163</td>\n",
       "      <td>0.866969</td>\n",
       "      <td>1.023563</td>\n",
       "      <td>1.088780</td>\n",
       "      <td>1.152049</td>\n",
       "      <td>0.842883</td>\n",
       "      <td>0.891214</td>\n",
       "      <td>1.112096</td>\n",
       "      <td>1.002524</td>\n",
       "      <td>1.031562</td>\n",
       "      <td>1.042673</td>\n",
       "      <td>0.982164</td>\n",
       "      <td>1.165057</td>\n",
       "      <td>0.973574</td>\n",
       "      <td>0.939535</td>\n",
       "      <td>1.107953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730175</td>\n",
       "      <td>0.699556</td>\n",
       "      <td>0.673700</td>\n",
       "      <td>0.662072</td>\n",
       "      <td>0.653056</td>\n",
       "      <td>0.636839</td>\n",
       "      <td>0.720679</td>\n",
       "      <td>0.643880</td>\n",
       "      <td>0.542382</td>\n",
       "      <td>0.667748</td>\n",
       "      <td>0.728863</td>\n",
       "      <td>0.591511</td>\n",
       "      <td>0.588671</td>\n",
       "      <td>0.623791</td>\n",
       "      <td>0.604367</td>\n",
       "      <td>0.717579</td>\n",
       "      <td>0.716184</td>\n",
       "      <td>0.728600</td>\n",
       "      <td>0.809191</td>\n",
       "      <td>0.835630</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>0.748969</td>\n",
       "      <td>0.790636</td>\n",
       "      <td>0.735746</td>\n",
       "      <td>0.718552</td>\n",
       "      <td>0.750787</td>\n",
       "      <td>0.777957</td>\n",
       "      <td>0.748585</td>\n",
       "      <td>0.683396</td>\n",
       "      <td>0.681842</td>\n",
       "      <td>0.849851</td>\n",
       "      <td>0.857925</td>\n",
       "      <td>0.773472</td>\n",
       "      <td>0.670337</td>\n",
       "      <td>0.628301</td>\n",
       "      <td>0.721224</td>\n",
       "      <td>0.707150</td>\n",
       "      <td>0.783355</td>\n",
       "      <td>0.727580</td>\n",
       "      <td>0.692765</td>\n",
       "      <td>0.762835</td>\n",
       "      <td>0.709300</td>\n",
       "      <td>0.659228</td>\n",
       "      <td>0.652220</td>\n",
       "      <td>0.759352</td>\n",
       "      <td>0.837513</td>\n",
       "      <td>0.744902</td>\n",
       "      <td>0.661489</td>\n",
       "      <td>0.674855</td>\n",
       "      <td>0.678003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1924</td>\n",
       "      <td>53330</td>\n",
       "      <td>267</td>\n",
       "      <td>0.212605</td>\n",
       "      <td>1.080315</td>\n",
       "      <td>1.054255</td>\n",
       "      <td>1.186841</td>\n",
       "      <td>1.184086</td>\n",
       "      <td>1.049520</td>\n",
       "      <td>1.030066</td>\n",
       "      <td>1.138974</td>\n",
       "      <td>1.196202</td>\n",
       "      <td>0.992778</td>\n",
       "      <td>0.916529</td>\n",
       "      <td>1.080038</td>\n",
       "      <td>1.004420</td>\n",
       "      <td>0.986589</td>\n",
       "      <td>1.058829</td>\n",
       "      <td>0.970565</td>\n",
       "      <td>0.952958</td>\n",
       "      <td>0.982420</td>\n",
       "      <td>0.909557</td>\n",
       "      <td>0.850695</td>\n",
       "      <td>0.847845</td>\n",
       "      <td>0.961395</td>\n",
       "      <td>0.866690</td>\n",
       "      <td>0.829688</td>\n",
       "      <td>1.085925</td>\n",
       "      <td>1.097143</td>\n",
       "      <td>0.914356</td>\n",
       "      <td>0.840732</td>\n",
       "      <td>0.813613</td>\n",
       "      <td>0.687617</td>\n",
       "      <td>0.757528</td>\n",
       "      <td>0.818865</td>\n",
       "      <td>0.826454</td>\n",
       "      <td>0.893545</td>\n",
       "      <td>0.869621</td>\n",
       "      <td>0.924727</td>\n",
       "      <td>0.973604</td>\n",
       "      <td>0.889258</td>\n",
       "      <td>0.854609</td>\n",
       "      <td>0.949721</td>\n",
       "      <td>0.908795</td>\n",
       "      <td>0.919749</td>\n",
       "      <td>0.995884</td>\n",
       "      <td>0.907267</td>\n",
       "      <td>0.923908</td>\n",
       "      <td>1.010974</td>\n",
       "      <td>1.136471</td>\n",
       "      <td>...</td>\n",
       "      <td>1.082616</td>\n",
       "      <td>0.865721</td>\n",
       "      <td>1.007884</td>\n",
       "      <td>0.700454</td>\n",
       "      <td>0.734717</td>\n",
       "      <td>1.103424</td>\n",
       "      <td>1.260457</td>\n",
       "      <td>1.185061</td>\n",
       "      <td>0.839313</td>\n",
       "      <td>0.923630</td>\n",
       "      <td>0.891176</td>\n",
       "      <td>0.826711</td>\n",
       "      <td>0.924907</td>\n",
       "      <td>1.016810</td>\n",
       "      <td>0.959748</td>\n",
       "      <td>0.999575</td>\n",
       "      <td>1.005594</td>\n",
       "      <td>0.895515</td>\n",
       "      <td>0.896164</td>\n",
       "      <td>0.796196</td>\n",
       "      <td>0.852573</td>\n",
       "      <td>0.926231</td>\n",
       "      <td>0.981716</td>\n",
       "      <td>0.947473</td>\n",
       "      <td>0.765692</td>\n",
       "      <td>0.868425</td>\n",
       "      <td>0.886143</td>\n",
       "      <td>0.760027</td>\n",
       "      <td>0.716643</td>\n",
       "      <td>0.788582</td>\n",
       "      <td>0.969161</td>\n",
       "      <td>0.944397</td>\n",
       "      <td>0.834727</td>\n",
       "      <td>0.837527</td>\n",
       "      <td>0.748598</td>\n",
       "      <td>0.786688</td>\n",
       "      <td>0.795698</td>\n",
       "      <td>0.721892</td>\n",
       "      <td>0.891034</td>\n",
       "      <td>0.984194</td>\n",
       "      <td>0.900125</td>\n",
       "      <td>0.768372</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.845616</td>\n",
       "      <td>0.793658</td>\n",
       "      <td>0.875271</td>\n",
       "      <td>0.844571</td>\n",
       "      <td>0.944504</td>\n",
       "      <td>1.039832</td>\n",
       "      <td>1.056826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5440</td>\n",
       "      <td>55983</td>\n",
       "      <td>132</td>\n",
       "      <td>0.237888</td>\n",
       "      <td>0.307411</td>\n",
       "      <td>0.328071</td>\n",
       "      <td>0.401123</td>\n",
       "      <td>0.345888</td>\n",
       "      <td>0.322805</td>\n",
       "      <td>0.394305</td>\n",
       "      <td>0.399146</td>\n",
       "      <td>0.415215</td>\n",
       "      <td>0.443113</td>\n",
       "      <td>0.387901</td>\n",
       "      <td>0.374096</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.337764</td>\n",
       "      <td>0.323667</td>\n",
       "      <td>0.340958</td>\n",
       "      <td>0.349667</td>\n",
       "      <td>0.310963</td>\n",
       "      <td>0.329052</td>\n",
       "      <td>0.302891</td>\n",
       "      <td>0.341012</td>\n",
       "      <td>0.470976</td>\n",
       "      <td>0.446120</td>\n",
       "      <td>0.350933</td>\n",
       "      <td>0.320861</td>\n",
       "      <td>0.319385</td>\n",
       "      <td>0.400757</td>\n",
       "      <td>0.484627</td>\n",
       "      <td>0.434063</td>\n",
       "      <td>0.405239</td>\n",
       "      <td>0.473895</td>\n",
       "      <td>0.560074</td>\n",
       "      <td>0.553805</td>\n",
       "      <td>0.602913</td>\n",
       "      <td>0.641709</td>\n",
       "      <td>0.500848</td>\n",
       "      <td>0.457737</td>\n",
       "      <td>0.467550</td>\n",
       "      <td>0.507088</td>\n",
       "      <td>0.564388</td>\n",
       "      <td>0.494300</td>\n",
       "      <td>0.467353</td>\n",
       "      <td>0.525493</td>\n",
       "      <td>0.529341</td>\n",
       "      <td>0.517859</td>\n",
       "      <td>0.560022</td>\n",
       "      <td>0.592124</td>\n",
       "      <td>...</td>\n",
       "      <td>1.235301</td>\n",
       "      <td>1.219081</td>\n",
       "      <td>1.153333</td>\n",
       "      <td>1.183530</td>\n",
       "      <td>1.282831</td>\n",
       "      <td>1.293188</td>\n",
       "      <td>1.282545</td>\n",
       "      <td>1.222786</td>\n",
       "      <td>1.273009</td>\n",
       "      <td>1.326470</td>\n",
       "      <td>1.264376</td>\n",
       "      <td>1.278182</td>\n",
       "      <td>1.314947</td>\n",
       "      <td>1.312632</td>\n",
       "      <td>1.293615</td>\n",
       "      <td>1.296667</td>\n",
       "      <td>1.266891</td>\n",
       "      <td>1.203230</td>\n",
       "      <td>1.204343</td>\n",
       "      <td>1.247096</td>\n",
       "      <td>1.273576</td>\n",
       "      <td>1.373208</td>\n",
       "      <td>1.427798</td>\n",
       "      <td>1.344045</td>\n",
       "      <td>1.308270</td>\n",
       "      <td>1.304600</td>\n",
       "      <td>1.294358</td>\n",
       "      <td>1.332443</td>\n",
       "      <td>1.340640</td>\n",
       "      <td>1.306784</td>\n",
       "      <td>1.312431</td>\n",
       "      <td>1.301884</td>\n",
       "      <td>1.303640</td>\n",
       "      <td>1.306043</td>\n",
       "      <td>1.291952</td>\n",
       "      <td>1.302044</td>\n",
       "      <td>1.282626</td>\n",
       "      <td>1.269255</td>\n",
       "      <td>1.251645</td>\n",
       "      <td>1.265311</td>\n",
       "      <td>1.283185</td>\n",
       "      <td>1.260953</td>\n",
       "      <td>1.278732</td>\n",
       "      <td>1.266610</td>\n",
       "      <td>1.256040</td>\n",
       "      <td>1.303732</td>\n",
       "      <td>1.329898</td>\n",
       "      <td>1.314732</td>\n",
       "      <td>1.285002</td>\n",
       "      <td>1.273627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PLATE    MJD  FIBER         Z  3868.645565753641  3869.535542582065  \\\n",
       "0   2099  53469    148  0.077807           0.636552           0.367806   \n",
       "1   1815  53884      1  0.091045           0.924821           0.955832   \n",
       "2    699  52202     92  0.043789           1.258258           1.268783   \n",
       "3   1924  53330    267  0.212605           1.080315           1.054255   \n",
       "4   5440  55983    132  0.237888           0.307411           0.328071   \n",
       "\n",
       "   3870.4278489317717  3871.318235772099  3872.2109532069176  \\\n",
       "0            0.278396           0.285307            0.183786   \n",
       "1            0.954143           0.935017            0.832751   \n",
       "2            1.352357           1.341881            1.336860   \n",
       "3            1.186841           1.184086            1.049520   \n",
       "4            0.401123           0.345888            0.322805   \n",
       "\n",
       "   3873.1017502480395  3873.992752215851  3874.8860863882537  \\\n",
       "0            0.328635           0.450617            0.433929   \n",
       "1            0.854249           0.846123            0.740990   \n",
       "2            1.250001           0.957059            0.828157   \n",
       "3            1.030066           1.138974            1.196202   \n",
       "4            0.394305           0.399146            0.415215   \n",
       "\n",
       "   3875.777498840249  3876.671244571283  3877.563067696571  3878.45722517584  \\\n",
       "0           0.899009           0.643836           0.475315          0.438675   \n",
       "1           0.776660           0.833628           0.880842          0.866295   \n",
       "2           1.033551           1.245475           1.137744          0.829527   \n",
       "3           0.992778           0.916529           1.080038          1.004420   \n",
       "4           0.443113           0.387901           0.374096          0.360839   \n",
       "\n",
       "   3879.3494591636186  3880.2440285808143  3881.136673620369  \\\n",
       "0            0.467904            0.417998           0.323266   \n",
       "1            0.799464            0.879522           0.877655   \n",
       "2            0.732822            0.620484           0.690629   \n",
       "3            0.986589            1.058829           0.970565   \n",
       "4            0.337764            0.323667           0.340958   \n",
       "\n",
       "   3882.029524011743  3882.924711445972  3883.8179731730975  \\\n",
       "0           0.554133           0.877506            0.547206   \n",
       "1           0.809836           0.658508            0.459713   \n",
       "2           0.910615           0.772459            0.725904   \n",
       "3           0.952958           0.982420            0.909557   \n",
       "4           0.349667           0.310963            0.329052   \n",
       "\n",
       "   3884.713573019754  3885.6072462721336  3886.503258721214  \\\n",
       "0           0.296718            0.674742           0.606375   \n",
       "1           0.461437            0.597803           0.624169   \n",
       "2           0.839652            0.876705           0.870031   \n",
       "3           0.850695            0.847845           0.961395   \n",
       "4           0.302891            0.341012           0.470976   \n",
       "\n",
       "   3887.3973436884376  3888.291634338733  3889.188265801773  \\\n",
       "0            0.222630           0.451282           0.314469   \n",
       "1            0.539646           0.642504           0.783469   \n",
       "2            0.748934           0.776170           0.772296   \n",
       "3            0.866690           0.829688           1.085925   \n",
       "4            0.446120           0.350933           0.320861   \n",
       "\n",
       "   3890.082968451347  3890.980012992077  3891.8751278307373  \\\n",
       "0           0.190128           0.553508            0.495501   \n",
       "1           0.816040           0.770628            0.738639   \n",
       "2           0.753819           0.862681            0.692442   \n",
       "3           1.097143           0.914356            0.840732   \n",
       "4           0.319385           0.400757            0.484627   \n",
       "\n",
       "   3892.772585639461  3893.668112857104  3894.5638460896052  \\\n",
       "0           0.428374           1.490322            0.988478   \n",
       "1           0.680130           0.671148            0.666353   \n",
       "2           0.552839           0.605622            0.583866   \n",
       "3           0.813613           0.687617            0.757528   \n",
       "4           0.434063           0.405239            0.473895   \n",
       "\n",
       "   3895.461923910823  3896.3580698071996  3897.2565613724432  \\\n",
       "0           0.554287            0.655043            0.784162   \n",
       "1           0.646091            0.744776            0.752563   \n",
       "2           0.573163            0.866969            1.023563   \n",
       "3           0.818865            0.826454            0.893545   \n",
       "4           0.560074            0.553805            0.602913   \n",
       "\n",
       "   3898.15312012281  3899.052025622691  3899.9489974172493  \\\n",
       "0          0.499813           0.408123            0.484755   \n",
       "1          0.641500           0.638825            0.777697   \n",
       "2          1.088780           1.152049            0.842883   \n",
       "3          0.869621           0.924727            0.973604   \n",
       "4          0.641709           0.500848            0.457737   \n",
       "\n",
       "   3900.8461755589897  3901.745702071507  3902.643293542793  \\\n",
       "0            0.473120           0.623950           0.716056   \n",
       "1            0.875334           0.836110           0.780308   \n",
       "2            0.891214           1.112096           1.002524   \n",
       "3            0.889258           0.854609           0.949721   \n",
       "4            0.467550           0.507088           0.564388   \n",
       "\n",
       "   3903.543234466747  3904.4412394579995  3905.3415949843097  \\\n",
       "0           0.306379            0.408779            0.382334   \n",
       "1           0.769351            0.740468            0.693389   \n",
       "2           1.031562            1.042673            0.982164   \n",
       "3           0.908795            0.919749            0.995884   \n",
       "4           0.494300            0.467353            0.525493   \n",
       "\n",
       "   3906.2400136860347  3907.1386390678003  3908.039616608505  \\\n",
       "0            0.384830            0.556806           0.535645   \n",
       "1            0.687770            0.675530           0.765399   \n",
       "2            1.165057            0.973574           0.939535   \n",
       "3            0.907267            0.923908           1.010974   \n",
       "4            0.529341            0.517859           0.560022   \n",
       "\n",
       "   3908.9386559865584  ...  7417.524757252301  7419.2311490749735  \\\n",
       "0            0.374631  ...           1.403149            1.300737   \n",
       "1            0.892660  ...           0.779851            0.728282   \n",
       "2            1.107953  ...           0.730175            0.699556   \n",
       "3            1.136471  ...           1.082616            0.865721   \n",
       "4            0.592124  ...           1.235301            1.219081   \n",
       "\n",
       "   7420.942007391534  7422.649185348109  7424.356756038729  7426.068796308937  \\\n",
       "0           0.854908           1.036072           1.284790           1.174821   \n",
       "1           0.705656           0.796199           0.861313           0.789964   \n",
       "2           0.673700           0.662072           0.653056           0.636839   \n",
       "3           1.007884           0.700454           0.734717           1.103424   \n",
       "4           1.153333           1.183530           1.282831           1.293188   \n",
       "\n",
       "   7427.777153676565  7429.489982682914  7431.199127089972  7432.91274519583  \\\n",
       "0           1.219686           1.320632           1.182485          1.149967   \n",
       "1           0.813254           0.877838           0.832707          0.821114   \n",
       "2           0.720679           0.643880           0.542382          0.667748   \n",
       "3           1.260457           1.185061           0.839313          0.923630   \n",
       "4           1.282545           1.222786           1.273009          1.326470   \n",
       "\n",
       "   7434.622677004906  7436.333002181546  7438.047804147664  7439.758917270303  \\\n",
       "0           1.135212           1.197466           1.170419           1.177966   \n",
       "1           0.850069           0.809483           0.786298           0.802253   \n",
       "2           0.728863           0.591511           0.588671           0.623791   \n",
       "3           0.891176           0.826711           0.924907           1.016810   \n",
       "4           1.264376           1.278182           1.314947           1.312632   \n",
       "\n",
       "   7441.474509244873  7443.186410676516  7444.902793023495  7446.615483127316  \\\n",
       "0           1.258235           1.338014           0.992609           1.281974   \n",
       "1           0.844928           0.827333           0.783233           0.829814   \n",
       "2           0.604367           0.717579           0.716184           0.728600   \n",
       "3           0.959748           0.999575           1.005594           0.895515   \n",
       "4           1.293615           1.296667           1.266891           1.203230   \n",
       "\n",
       "   7448.328567233246  7450.0461353501705  7451.760008673134  \\\n",
       "0           1.229110            1.421697           1.077822   \n",
       "1           0.783733            0.794661           0.810325   \n",
       "2           0.809191            0.835630           0.755814   \n",
       "3           0.896164            0.796196           0.852573   \n",
       "4           1.204343            1.247096           1.273576   \n",
       "\n",
       "   7453.478368072875  7455.1930309764675  7456.9121820235705  \\\n",
       "0           1.240584            1.259480            1.368396   \n",
       "1           0.747440            0.753007            0.828389   \n",
       "2           0.748969            0.790636            0.735746   \n",
       "3           0.926231            0.981716            0.947473   \n",
       "4           1.373208            1.427798            1.344045   \n",
       "\n",
       "   7458.627634871548  7460.3434823572  7462.063821087017  7463.78045906279  \\\n",
       "0           0.990141         1.229603           1.239413          1.142440   \n",
       "1           0.864708         0.812884           0.745643          0.751192   \n",
       "2           0.718552         0.750787           0.777957          0.748585   \n",
       "3           0.765692         0.868425           0.886143          0.760027   \n",
       "4           1.308270         1.304600           1.294358          1.332443   \n",
       "\n",
       "   7465.501590351842  7467.219019181919  7468.940943395341  7470.659163444065  \\\n",
       "0           1.154854           1.272670           1.196519           1.218197   \n",
       "1           0.838403           0.857025           0.785440           0.767616   \n",
       "2           0.683396           0.681842           0.849851           0.857925   \n",
       "3           0.716643           0.788582           0.969161           0.944397   \n",
       "4           1.340640           1.306784           1.312431           1.301884   \n",
       "\n",
       "   7472.377778767054  7474.100892579042  7475.820299667295  7477.544207317  \\\n",
       "0           1.355392           1.242389           1.247098        1.202379   \n",
       "1           0.743195           0.724839           0.805945        0.840591   \n",
       "2           0.773472           0.670337           0.628301        0.721224   \n",
       "3           0.834727           0.837527           0.748598        0.786688   \n",
       "4           1.303640           1.306043           1.291952        1.302044   \n",
       "\n",
       "   7479.264406535282  7480.989108388424  7482.710100101674  7484.431487726802  \\\n",
       "0           0.861311           1.392254           1.273615           1.089576   \n",
       "1           0.810032           0.829138           0.850290           0.763131   \n",
       "2           0.707150           0.783355           0.727580           0.692765   \n",
       "3           0.795698           0.721892           0.891034           0.984194   \n",
       "4           1.282626           1.269255           1.251645           1.265311   \n",
       "\n",
       "   7486.157381097453  7487.879561765048  7489.606250253956  7491.329224329366  \\\n",
       "0           1.155214           1.211078           1.142575           1.233846   \n",
       "1           0.688105           0.779044           0.817667           0.815495   \n",
       "2           0.762835           0.709300           0.659228           0.652220   \n",
       "3           0.900125           0.768372           0.815000           0.845616   \n",
       "4           1.283185           1.260953           1.278732           1.266610   \n",
       "\n",
       "   7493.0567083028445  7494.7804761515945  7496.504640550872  \\\n",
       "0            1.084954            1.169770           1.161821   \n",
       "1            0.831063            0.807701           0.825111   \n",
       "2            0.759352            0.837513           0.744902   \n",
       "3            0.793658            0.875271           0.844571   \n",
       "4            1.256040            1.303732           1.329898   \n",
       "\n",
       "   7498.233317963899  7499.958276684899  7501.6877504987915  \n",
       "0           1.160405           1.275585            1.238802  \n",
       "1           0.779291           0.775595            0.852922  \n",
       "2           0.661489           0.674855            0.678003  \n",
       "3           0.944504           1.039832            1.056826  \n",
       "4           1.314732           1.285002            1.273627  \n",
       "\n",
       "[5 rows x 2881 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_origen = pd.read_csv(\"./data/datasetV3_3KRandom.csv\", sep=\";\")\n",
    "data_origen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T19:10:03.767387Z",
     "start_time": "2019-11-03T19:10:01.992605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3868.645565753641</th>\n",
       "      <th>3869.535542582065</th>\n",
       "      <th>3870.4278489317717</th>\n",
       "      <th>3871.318235772099</th>\n",
       "      <th>3872.2109532069176</th>\n",
       "      <th>3873.1017502480395</th>\n",
       "      <th>3873.992752215851</th>\n",
       "      <th>3874.8860863882537</th>\n",
       "      <th>3875.777498840249</th>\n",
       "      <th>3876.671244571283</th>\n",
       "      <th>3877.563067696571</th>\n",
       "      <th>3878.45722517584</th>\n",
       "      <th>3879.3494591636186</th>\n",
       "      <th>3880.2440285808143</th>\n",
       "      <th>3881.136673620369</th>\n",
       "      <th>3882.029524011743</th>\n",
       "      <th>3882.924711445972</th>\n",
       "      <th>3883.8179731730975</th>\n",
       "      <th>3884.713573019754</th>\n",
       "      <th>3885.6072462721336</th>\n",
       "      <th>3886.503258721214</th>\n",
       "      <th>3887.3973436884376</th>\n",
       "      <th>3888.291634338733</th>\n",
       "      <th>3889.188265801773</th>\n",
       "      <th>3890.082968451347</th>\n",
       "      <th>3890.980012992077</th>\n",
       "      <th>3891.8751278307373</th>\n",
       "      <th>3892.772585639461</th>\n",
       "      <th>3893.668112857104</th>\n",
       "      <th>3894.5638460896052</th>\n",
       "      <th>3895.461923910823</th>\n",
       "      <th>3896.3580698071996</th>\n",
       "      <th>3897.2565613724432</th>\n",
       "      <th>3898.15312012281</th>\n",
       "      <th>3899.052025622691</th>\n",
       "      <th>3899.9489974172493</th>\n",
       "      <th>3900.8461755589897</th>\n",
       "      <th>3901.745702071507</th>\n",
       "      <th>3902.643293542793</th>\n",
       "      <th>3903.543234466747</th>\n",
       "      <th>3904.4412394579995</th>\n",
       "      <th>3905.3415949843097</th>\n",
       "      <th>3906.2400136860347</th>\n",
       "      <th>3907.1386390678003</th>\n",
       "      <th>3908.039616608505</th>\n",
       "      <th>3908.9386559865584</th>\n",
       "      <th>3909.8400486071882</th>\n",
       "      <th>3910.7395021722573</th>\n",
       "      <th>3911.6413100640398</th>\n",
       "      <th>3912.541178006939</th>\n",
       "      <th>...</th>\n",
       "      <th>7417.524757252301</th>\n",
       "      <th>7419.2311490749735</th>\n",
       "      <th>7420.942007391534</th>\n",
       "      <th>7422.649185348109</th>\n",
       "      <th>7424.356756038729</th>\n",
       "      <th>7426.068796308937</th>\n",
       "      <th>7427.777153676565</th>\n",
       "      <th>7429.489982682914</th>\n",
       "      <th>7431.199127089972</th>\n",
       "      <th>7432.91274519583</th>\n",
       "      <th>7434.622677004906</th>\n",
       "      <th>7436.333002181546</th>\n",
       "      <th>7438.047804147664</th>\n",
       "      <th>7439.758917270303</th>\n",
       "      <th>7441.474509244873</th>\n",
       "      <th>7443.186410676516</th>\n",
       "      <th>7444.902793023495</th>\n",
       "      <th>7446.615483127316</th>\n",
       "      <th>7448.328567233246</th>\n",
       "      <th>7450.0461353501705</th>\n",
       "      <th>7451.760008673134</th>\n",
       "      <th>7453.478368072875</th>\n",
       "      <th>7455.1930309764675</th>\n",
       "      <th>7456.9121820235705</th>\n",
       "      <th>7458.627634871548</th>\n",
       "      <th>7460.3434823572</th>\n",
       "      <th>7462.063821087017</th>\n",
       "      <th>7463.78045906279</th>\n",
       "      <th>7465.501590351842</th>\n",
       "      <th>7467.219019181919</th>\n",
       "      <th>7468.940943395341</th>\n",
       "      <th>7470.659163444065</th>\n",
       "      <th>7472.377778767054</th>\n",
       "      <th>7474.100892579042</th>\n",
       "      <th>7475.820299667295</th>\n",
       "      <th>7477.544207317</th>\n",
       "      <th>7479.264406535282</th>\n",
       "      <th>7480.989108388424</th>\n",
       "      <th>7482.710100101674</th>\n",
       "      <th>7484.431487726802</th>\n",
       "      <th>7486.157381097453</th>\n",
       "      <th>7487.879561765048</th>\n",
       "      <th>7489.606250253956</th>\n",
       "      <th>7491.329224329366</th>\n",
       "      <th>7493.0567083028445</th>\n",
       "      <th>7494.7804761515945</th>\n",
       "      <th>7496.504640550872</th>\n",
       "      <th>7498.233317963899</th>\n",
       "      <th>7499.958276684899</th>\n",
       "      <th>7501.6877504987915</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.924821</td>\n",
       "      <td>0.955832</td>\n",
       "      <td>0.954143</td>\n",
       "      <td>0.935017</td>\n",
       "      <td>0.832751</td>\n",
       "      <td>0.854249</td>\n",
       "      <td>0.846123</td>\n",
       "      <td>0.740990</td>\n",
       "      <td>0.776660</td>\n",
       "      <td>0.833628</td>\n",
       "      <td>0.880842</td>\n",
       "      <td>0.866295</td>\n",
       "      <td>0.799464</td>\n",
       "      <td>0.879522</td>\n",
       "      <td>0.877655</td>\n",
       "      <td>0.809836</td>\n",
       "      <td>0.658508</td>\n",
       "      <td>0.459713</td>\n",
       "      <td>0.461437</td>\n",
       "      <td>0.597803</td>\n",
       "      <td>0.624169</td>\n",
       "      <td>0.539646</td>\n",
       "      <td>0.642504</td>\n",
       "      <td>0.783469</td>\n",
       "      <td>0.816040</td>\n",
       "      <td>0.770628</td>\n",
       "      <td>0.738639</td>\n",
       "      <td>0.680130</td>\n",
       "      <td>0.671148</td>\n",
       "      <td>0.666353</td>\n",
       "      <td>0.646091</td>\n",
       "      <td>0.744776</td>\n",
       "      <td>0.752563</td>\n",
       "      <td>0.641500</td>\n",
       "      <td>0.638825</td>\n",
       "      <td>0.777697</td>\n",
       "      <td>0.875334</td>\n",
       "      <td>0.836110</td>\n",
       "      <td>0.780308</td>\n",
       "      <td>0.769351</td>\n",
       "      <td>0.740468</td>\n",
       "      <td>0.693389</td>\n",
       "      <td>0.687770</td>\n",
       "      <td>0.675530</td>\n",
       "      <td>0.765399</td>\n",
       "      <td>0.892660</td>\n",
       "      <td>0.813037</td>\n",
       "      <td>0.865628</td>\n",
       "      <td>0.984975</td>\n",
       "      <td>0.975004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779851</td>\n",
       "      <td>0.728282</td>\n",
       "      <td>0.705656</td>\n",
       "      <td>0.796199</td>\n",
       "      <td>0.861313</td>\n",
       "      <td>0.789964</td>\n",
       "      <td>0.813254</td>\n",
       "      <td>0.877838</td>\n",
       "      <td>0.832707</td>\n",
       "      <td>0.821114</td>\n",
       "      <td>0.850069</td>\n",
       "      <td>0.809483</td>\n",
       "      <td>0.786298</td>\n",
       "      <td>0.802253</td>\n",
       "      <td>0.844928</td>\n",
       "      <td>0.827333</td>\n",
       "      <td>0.783233</td>\n",
       "      <td>0.829814</td>\n",
       "      <td>0.783733</td>\n",
       "      <td>0.794661</td>\n",
       "      <td>0.810325</td>\n",
       "      <td>0.747440</td>\n",
       "      <td>0.753007</td>\n",
       "      <td>0.828389</td>\n",
       "      <td>0.864708</td>\n",
       "      <td>0.812884</td>\n",
       "      <td>0.745643</td>\n",
       "      <td>0.751192</td>\n",
       "      <td>0.838403</td>\n",
       "      <td>0.857025</td>\n",
       "      <td>0.785440</td>\n",
       "      <td>0.767616</td>\n",
       "      <td>0.743195</td>\n",
       "      <td>0.724839</td>\n",
       "      <td>0.805945</td>\n",
       "      <td>0.840591</td>\n",
       "      <td>0.810032</td>\n",
       "      <td>0.829138</td>\n",
       "      <td>0.850290</td>\n",
       "      <td>0.763131</td>\n",
       "      <td>0.688105</td>\n",
       "      <td>0.779044</td>\n",
       "      <td>0.817667</td>\n",
       "      <td>0.815495</td>\n",
       "      <td>0.831063</td>\n",
       "      <td>0.807701</td>\n",
       "      <td>0.825111</td>\n",
       "      <td>0.779291</td>\n",
       "      <td>0.775595</td>\n",
       "      <td>0.852922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.258258</td>\n",
       "      <td>1.268783</td>\n",
       "      <td>1.352357</td>\n",
       "      <td>1.341881</td>\n",
       "      <td>1.336860</td>\n",
       "      <td>1.250001</td>\n",
       "      <td>0.957059</td>\n",
       "      <td>0.828157</td>\n",
       "      <td>1.033551</td>\n",
       "      <td>1.245475</td>\n",
       "      <td>1.137744</td>\n",
       "      <td>0.829527</td>\n",
       "      <td>0.732822</td>\n",
       "      <td>0.620484</td>\n",
       "      <td>0.690629</td>\n",
       "      <td>0.910615</td>\n",
       "      <td>0.772459</td>\n",
       "      <td>0.725904</td>\n",
       "      <td>0.839652</td>\n",
       "      <td>0.876705</td>\n",
       "      <td>0.870031</td>\n",
       "      <td>0.748934</td>\n",
       "      <td>0.776170</td>\n",
       "      <td>0.772296</td>\n",
       "      <td>0.753819</td>\n",
       "      <td>0.862681</td>\n",
       "      <td>0.692442</td>\n",
       "      <td>0.552839</td>\n",
       "      <td>0.605622</td>\n",
       "      <td>0.583866</td>\n",
       "      <td>0.573163</td>\n",
       "      <td>0.866969</td>\n",
       "      <td>1.023563</td>\n",
       "      <td>1.088780</td>\n",
       "      <td>1.152049</td>\n",
       "      <td>0.842883</td>\n",
       "      <td>0.891214</td>\n",
       "      <td>1.112096</td>\n",
       "      <td>1.002524</td>\n",
       "      <td>1.031562</td>\n",
       "      <td>1.042673</td>\n",
       "      <td>0.982164</td>\n",
       "      <td>1.165057</td>\n",
       "      <td>0.973574</td>\n",
       "      <td>0.939535</td>\n",
       "      <td>1.107953</td>\n",
       "      <td>0.978757</td>\n",
       "      <td>1.160724</td>\n",
       "      <td>1.187305</td>\n",
       "      <td>0.925614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730175</td>\n",
       "      <td>0.699556</td>\n",
       "      <td>0.673700</td>\n",
       "      <td>0.662072</td>\n",
       "      <td>0.653056</td>\n",
       "      <td>0.636839</td>\n",
       "      <td>0.720679</td>\n",
       "      <td>0.643880</td>\n",
       "      <td>0.542382</td>\n",
       "      <td>0.667748</td>\n",
       "      <td>0.728863</td>\n",
       "      <td>0.591511</td>\n",
       "      <td>0.588671</td>\n",
       "      <td>0.623791</td>\n",
       "      <td>0.604367</td>\n",
       "      <td>0.717579</td>\n",
       "      <td>0.716184</td>\n",
       "      <td>0.728600</td>\n",
       "      <td>0.809191</td>\n",
       "      <td>0.835630</td>\n",
       "      <td>0.755814</td>\n",
       "      <td>0.748969</td>\n",
       "      <td>0.790636</td>\n",
       "      <td>0.735746</td>\n",
       "      <td>0.718552</td>\n",
       "      <td>0.750787</td>\n",
       "      <td>0.777957</td>\n",
       "      <td>0.748585</td>\n",
       "      <td>0.683396</td>\n",
       "      <td>0.681842</td>\n",
       "      <td>0.849851</td>\n",
       "      <td>0.857925</td>\n",
       "      <td>0.773472</td>\n",
       "      <td>0.670337</td>\n",
       "      <td>0.628301</td>\n",
       "      <td>0.721224</td>\n",
       "      <td>0.707150</td>\n",
       "      <td>0.783355</td>\n",
       "      <td>0.727580</td>\n",
       "      <td>0.692765</td>\n",
       "      <td>0.762835</td>\n",
       "      <td>0.709300</td>\n",
       "      <td>0.659228</td>\n",
       "      <td>0.652220</td>\n",
       "      <td>0.759352</td>\n",
       "      <td>0.837513</td>\n",
       "      <td>0.744902</td>\n",
       "      <td>0.661489</td>\n",
       "      <td>0.674855</td>\n",
       "      <td>0.678003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.080315</td>\n",
       "      <td>1.054255</td>\n",
       "      <td>1.186841</td>\n",
       "      <td>1.184086</td>\n",
       "      <td>1.049520</td>\n",
       "      <td>1.030066</td>\n",
       "      <td>1.138974</td>\n",
       "      <td>1.196202</td>\n",
       "      <td>0.992778</td>\n",
       "      <td>0.916529</td>\n",
       "      <td>1.080038</td>\n",
       "      <td>1.004420</td>\n",
       "      <td>0.986589</td>\n",
       "      <td>1.058829</td>\n",
       "      <td>0.970565</td>\n",
       "      <td>0.952958</td>\n",
       "      <td>0.982420</td>\n",
       "      <td>0.909557</td>\n",
       "      <td>0.850695</td>\n",
       "      <td>0.847845</td>\n",
       "      <td>0.961395</td>\n",
       "      <td>0.866690</td>\n",
       "      <td>0.829688</td>\n",
       "      <td>1.085925</td>\n",
       "      <td>1.097143</td>\n",
       "      <td>0.914356</td>\n",
       "      <td>0.840732</td>\n",
       "      <td>0.813613</td>\n",
       "      <td>0.687617</td>\n",
       "      <td>0.757528</td>\n",
       "      <td>0.818865</td>\n",
       "      <td>0.826454</td>\n",
       "      <td>0.893545</td>\n",
       "      <td>0.869621</td>\n",
       "      <td>0.924727</td>\n",
       "      <td>0.973604</td>\n",
       "      <td>0.889258</td>\n",
       "      <td>0.854609</td>\n",
       "      <td>0.949721</td>\n",
       "      <td>0.908795</td>\n",
       "      <td>0.919749</td>\n",
       "      <td>0.995884</td>\n",
       "      <td>0.907267</td>\n",
       "      <td>0.923908</td>\n",
       "      <td>1.010974</td>\n",
       "      <td>1.136471</td>\n",
       "      <td>1.077017</td>\n",
       "      <td>0.946960</td>\n",
       "      <td>1.062866</td>\n",
       "      <td>1.027863</td>\n",
       "      <td>...</td>\n",
       "      <td>1.082616</td>\n",
       "      <td>0.865721</td>\n",
       "      <td>1.007884</td>\n",
       "      <td>0.700454</td>\n",
       "      <td>0.734717</td>\n",
       "      <td>1.103424</td>\n",
       "      <td>1.260457</td>\n",
       "      <td>1.185061</td>\n",
       "      <td>0.839313</td>\n",
       "      <td>0.923630</td>\n",
       "      <td>0.891176</td>\n",
       "      <td>0.826711</td>\n",
       "      <td>0.924907</td>\n",
       "      <td>1.016810</td>\n",
       "      <td>0.959748</td>\n",
       "      <td>0.999575</td>\n",
       "      <td>1.005594</td>\n",
       "      <td>0.895515</td>\n",
       "      <td>0.896164</td>\n",
       "      <td>0.796196</td>\n",
       "      <td>0.852573</td>\n",
       "      <td>0.926231</td>\n",
       "      <td>0.981716</td>\n",
       "      <td>0.947473</td>\n",
       "      <td>0.765692</td>\n",
       "      <td>0.868425</td>\n",
       "      <td>0.886143</td>\n",
       "      <td>0.760027</td>\n",
       "      <td>0.716643</td>\n",
       "      <td>0.788582</td>\n",
       "      <td>0.969161</td>\n",
       "      <td>0.944397</td>\n",
       "      <td>0.834727</td>\n",
       "      <td>0.837527</td>\n",
       "      <td>0.748598</td>\n",
       "      <td>0.786688</td>\n",
       "      <td>0.795698</td>\n",
       "      <td>0.721892</td>\n",
       "      <td>0.891034</td>\n",
       "      <td>0.984194</td>\n",
       "      <td>0.900125</td>\n",
       "      <td>0.768372</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.845616</td>\n",
       "      <td>0.793658</td>\n",
       "      <td>0.875271</td>\n",
       "      <td>0.844571</td>\n",
       "      <td>0.944504</td>\n",
       "      <td>1.039832</td>\n",
       "      <td>1.056826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.307411</td>\n",
       "      <td>0.328071</td>\n",
       "      <td>0.401123</td>\n",
       "      <td>0.345888</td>\n",
       "      <td>0.322805</td>\n",
       "      <td>0.394305</td>\n",
       "      <td>0.399146</td>\n",
       "      <td>0.415215</td>\n",
       "      <td>0.443113</td>\n",
       "      <td>0.387901</td>\n",
       "      <td>0.374096</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.337764</td>\n",
       "      <td>0.323667</td>\n",
       "      <td>0.340958</td>\n",
       "      <td>0.349667</td>\n",
       "      <td>0.310963</td>\n",
       "      <td>0.329052</td>\n",
       "      <td>0.302891</td>\n",
       "      <td>0.341012</td>\n",
       "      <td>0.470976</td>\n",
       "      <td>0.446120</td>\n",
       "      <td>0.350933</td>\n",
       "      <td>0.320861</td>\n",
       "      <td>0.319385</td>\n",
       "      <td>0.400757</td>\n",
       "      <td>0.484627</td>\n",
       "      <td>0.434063</td>\n",
       "      <td>0.405239</td>\n",
       "      <td>0.473895</td>\n",
       "      <td>0.560074</td>\n",
       "      <td>0.553805</td>\n",
       "      <td>0.602913</td>\n",
       "      <td>0.641709</td>\n",
       "      <td>0.500848</td>\n",
       "      <td>0.457737</td>\n",
       "      <td>0.467550</td>\n",
       "      <td>0.507088</td>\n",
       "      <td>0.564388</td>\n",
       "      <td>0.494300</td>\n",
       "      <td>0.467353</td>\n",
       "      <td>0.525493</td>\n",
       "      <td>0.529341</td>\n",
       "      <td>0.517859</td>\n",
       "      <td>0.560022</td>\n",
       "      <td>0.592124</td>\n",
       "      <td>0.589732</td>\n",
       "      <td>0.542784</td>\n",
       "      <td>0.554171</td>\n",
       "      <td>0.549082</td>\n",
       "      <td>...</td>\n",
       "      <td>1.235301</td>\n",
       "      <td>1.219081</td>\n",
       "      <td>1.153333</td>\n",
       "      <td>1.183530</td>\n",
       "      <td>1.282831</td>\n",
       "      <td>1.293188</td>\n",
       "      <td>1.282545</td>\n",
       "      <td>1.222786</td>\n",
       "      <td>1.273009</td>\n",
       "      <td>1.326470</td>\n",
       "      <td>1.264376</td>\n",
       "      <td>1.278182</td>\n",
       "      <td>1.314947</td>\n",
       "      <td>1.312632</td>\n",
       "      <td>1.293615</td>\n",
       "      <td>1.296667</td>\n",
       "      <td>1.266891</td>\n",
       "      <td>1.203230</td>\n",
       "      <td>1.204343</td>\n",
       "      <td>1.247096</td>\n",
       "      <td>1.273576</td>\n",
       "      <td>1.373208</td>\n",
       "      <td>1.427798</td>\n",
       "      <td>1.344045</td>\n",
       "      <td>1.308270</td>\n",
       "      <td>1.304600</td>\n",
       "      <td>1.294358</td>\n",
       "      <td>1.332443</td>\n",
       "      <td>1.340640</td>\n",
       "      <td>1.306784</td>\n",
       "      <td>1.312431</td>\n",
       "      <td>1.301884</td>\n",
       "      <td>1.303640</td>\n",
       "      <td>1.306043</td>\n",
       "      <td>1.291952</td>\n",
       "      <td>1.302044</td>\n",
       "      <td>1.282626</td>\n",
       "      <td>1.269255</td>\n",
       "      <td>1.251645</td>\n",
       "      <td>1.265311</td>\n",
       "      <td>1.283185</td>\n",
       "      <td>1.260953</td>\n",
       "      <td>1.278732</td>\n",
       "      <td>1.266610</td>\n",
       "      <td>1.256040</td>\n",
       "      <td>1.303732</td>\n",
       "      <td>1.329898</td>\n",
       "      <td>1.314732</td>\n",
       "      <td>1.285002</td>\n",
       "      <td>1.273627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.362752</td>\n",
       "      <td>0.419963</td>\n",
       "      <td>0.427431</td>\n",
       "      <td>0.339278</td>\n",
       "      <td>0.331611</td>\n",
       "      <td>0.342064</td>\n",
       "      <td>0.311900</td>\n",
       "      <td>0.332671</td>\n",
       "      <td>0.329077</td>\n",
       "      <td>0.320231</td>\n",
       "      <td>0.373803</td>\n",
       "      <td>0.439510</td>\n",
       "      <td>0.492965</td>\n",
       "      <td>0.413532</td>\n",
       "      <td>0.382764</td>\n",
       "      <td>0.443150</td>\n",
       "      <td>0.449069</td>\n",
       "      <td>0.432200</td>\n",
       "      <td>0.387643</td>\n",
       "      <td>0.361394</td>\n",
       "      <td>0.316620</td>\n",
       "      <td>0.383708</td>\n",
       "      <td>0.433570</td>\n",
       "      <td>0.327515</td>\n",
       "      <td>0.336920</td>\n",
       "      <td>0.390605</td>\n",
       "      <td>0.407146</td>\n",
       "      <td>0.413626</td>\n",
       "      <td>0.439393</td>\n",
       "      <td>0.498497</td>\n",
       "      <td>0.496263</td>\n",
       "      <td>0.460546</td>\n",
       "      <td>0.494382</td>\n",
       "      <td>0.524688</td>\n",
       "      <td>0.457736</td>\n",
       "      <td>0.403213</td>\n",
       "      <td>0.445082</td>\n",
       "      <td>0.509527</td>\n",
       "      <td>0.553520</td>\n",
       "      <td>0.525515</td>\n",
       "      <td>0.488860</td>\n",
       "      <td>0.502896</td>\n",
       "      <td>0.468609</td>\n",
       "      <td>0.455022</td>\n",
       "      <td>0.471632</td>\n",
       "      <td>0.492226</td>\n",
       "      <td>0.533754</td>\n",
       "      <td>0.552509</td>\n",
       "      <td>0.561959</td>\n",
       "      <td>0.596420</td>\n",
       "      <td>...</td>\n",
       "      <td>1.111921</td>\n",
       "      <td>1.166919</td>\n",
       "      <td>1.188617</td>\n",
       "      <td>1.178303</td>\n",
       "      <td>1.149287</td>\n",
       "      <td>1.116060</td>\n",
       "      <td>1.161622</td>\n",
       "      <td>1.181562</td>\n",
       "      <td>1.179871</td>\n",
       "      <td>1.175125</td>\n",
       "      <td>1.150849</td>\n",
       "      <td>1.149428</td>\n",
       "      <td>1.153262</td>\n",
       "      <td>1.179789</td>\n",
       "      <td>1.169943</td>\n",
       "      <td>1.165257</td>\n",
       "      <td>1.179557</td>\n",
       "      <td>1.178521</td>\n",
       "      <td>1.212370</td>\n",
       "      <td>1.192431</td>\n",
       "      <td>1.185238</td>\n",
       "      <td>1.196087</td>\n",
       "      <td>1.176782</td>\n",
       "      <td>1.187024</td>\n",
       "      <td>1.181789</td>\n",
       "      <td>1.167352</td>\n",
       "      <td>1.154860</td>\n",
       "      <td>1.143830</td>\n",
       "      <td>1.151100</td>\n",
       "      <td>1.172506</td>\n",
       "      <td>1.184212</td>\n",
       "      <td>1.168895</td>\n",
       "      <td>1.170764</td>\n",
       "      <td>1.175588</td>\n",
       "      <td>1.164839</td>\n",
       "      <td>1.166674</td>\n",
       "      <td>1.153739</td>\n",
       "      <td>1.126513</td>\n",
       "      <td>1.124752</td>\n",
       "      <td>1.141948</td>\n",
       "      <td>1.152485</td>\n",
       "      <td>1.158272</td>\n",
       "      <td>1.176106</td>\n",
       "      <td>1.230612</td>\n",
       "      <td>1.252418</td>\n",
       "      <td>1.220164</td>\n",
       "      <td>1.192720</td>\n",
       "      <td>1.185559</td>\n",
       "      <td>1.184189</td>\n",
       "      <td>1.151777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2877 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   3868.645565753641  3869.535542582065  3870.4278489317717  \\\n",
       "0           0.924821           0.955832            0.954143   \n",
       "1           1.258258           1.268783            1.352357   \n",
       "2           1.080315           1.054255            1.186841   \n",
       "3           0.307411           0.328071            0.401123   \n",
       "4           0.362752           0.419963            0.427431   \n",
       "\n",
       "   3871.318235772099  3872.2109532069176  3873.1017502480395  \\\n",
       "0           0.935017            0.832751            0.854249   \n",
       "1           1.341881            1.336860            1.250001   \n",
       "2           1.184086            1.049520            1.030066   \n",
       "3           0.345888            0.322805            0.394305   \n",
       "4           0.339278            0.331611            0.342064   \n",
       "\n",
       "   3873.992752215851  3874.8860863882537  3875.777498840249  \\\n",
       "0           0.846123            0.740990           0.776660   \n",
       "1           0.957059            0.828157           1.033551   \n",
       "2           1.138974            1.196202           0.992778   \n",
       "3           0.399146            0.415215           0.443113   \n",
       "4           0.311900            0.332671           0.329077   \n",
       "\n",
       "   3876.671244571283  3877.563067696571  3878.45722517584  3879.3494591636186  \\\n",
       "0           0.833628           0.880842          0.866295            0.799464   \n",
       "1           1.245475           1.137744          0.829527            0.732822   \n",
       "2           0.916529           1.080038          1.004420            0.986589   \n",
       "3           0.387901           0.374096          0.360839            0.337764   \n",
       "4           0.320231           0.373803          0.439510            0.492965   \n",
       "\n",
       "   3880.2440285808143  3881.136673620369  3882.029524011743  \\\n",
       "0            0.879522           0.877655           0.809836   \n",
       "1            0.620484           0.690629           0.910615   \n",
       "2            1.058829           0.970565           0.952958   \n",
       "3            0.323667           0.340958           0.349667   \n",
       "4            0.413532           0.382764           0.443150   \n",
       "\n",
       "   3882.924711445972  3883.8179731730975  3884.713573019754  \\\n",
       "0           0.658508            0.459713           0.461437   \n",
       "1           0.772459            0.725904           0.839652   \n",
       "2           0.982420            0.909557           0.850695   \n",
       "3           0.310963            0.329052           0.302891   \n",
       "4           0.449069            0.432200           0.387643   \n",
       "\n",
       "   3885.6072462721336  3886.503258721214  3887.3973436884376  \\\n",
       "0            0.597803           0.624169            0.539646   \n",
       "1            0.876705           0.870031            0.748934   \n",
       "2            0.847845           0.961395            0.866690   \n",
       "3            0.341012           0.470976            0.446120   \n",
       "4            0.361394           0.316620            0.383708   \n",
       "\n",
       "   3888.291634338733  3889.188265801773  3890.082968451347  3890.980012992077  \\\n",
       "0           0.642504           0.783469           0.816040           0.770628   \n",
       "1           0.776170           0.772296           0.753819           0.862681   \n",
       "2           0.829688           1.085925           1.097143           0.914356   \n",
       "3           0.350933           0.320861           0.319385           0.400757   \n",
       "4           0.433570           0.327515           0.336920           0.390605   \n",
       "\n",
       "   3891.8751278307373  3892.772585639461  3893.668112857104  \\\n",
       "0            0.738639           0.680130           0.671148   \n",
       "1            0.692442           0.552839           0.605622   \n",
       "2            0.840732           0.813613           0.687617   \n",
       "3            0.484627           0.434063           0.405239   \n",
       "4            0.407146           0.413626           0.439393   \n",
       "\n",
       "   3894.5638460896052  3895.461923910823  3896.3580698071996  \\\n",
       "0            0.666353           0.646091            0.744776   \n",
       "1            0.583866           0.573163            0.866969   \n",
       "2            0.757528           0.818865            0.826454   \n",
       "3            0.473895           0.560074            0.553805   \n",
       "4            0.498497           0.496263            0.460546   \n",
       "\n",
       "   3897.2565613724432  3898.15312012281  3899.052025622691  \\\n",
       "0            0.752563          0.641500           0.638825   \n",
       "1            1.023563          1.088780           1.152049   \n",
       "2            0.893545          0.869621           0.924727   \n",
       "3            0.602913          0.641709           0.500848   \n",
       "4            0.494382          0.524688           0.457736   \n",
       "\n",
       "   3899.9489974172493  3900.8461755589897  3901.745702071507  \\\n",
       "0            0.777697            0.875334           0.836110   \n",
       "1            0.842883            0.891214           1.112096   \n",
       "2            0.973604            0.889258           0.854609   \n",
       "3            0.457737            0.467550           0.507088   \n",
       "4            0.403213            0.445082           0.509527   \n",
       "\n",
       "   3902.643293542793  3903.543234466747  3904.4412394579995  \\\n",
       "0           0.780308           0.769351            0.740468   \n",
       "1           1.002524           1.031562            1.042673   \n",
       "2           0.949721           0.908795            0.919749   \n",
       "3           0.564388           0.494300            0.467353   \n",
       "4           0.553520           0.525515            0.488860   \n",
       "\n",
       "   3905.3415949843097  3906.2400136860347  3907.1386390678003  \\\n",
       "0            0.693389            0.687770            0.675530   \n",
       "1            0.982164            1.165057            0.973574   \n",
       "2            0.995884            0.907267            0.923908   \n",
       "3            0.525493            0.529341            0.517859   \n",
       "4            0.502896            0.468609            0.455022   \n",
       "\n",
       "   3908.039616608505  3908.9386559865584  3909.8400486071882  \\\n",
       "0           0.765399            0.892660            0.813037   \n",
       "1           0.939535            1.107953            0.978757   \n",
       "2           1.010974            1.136471            1.077017   \n",
       "3           0.560022            0.592124            0.589732   \n",
       "4           0.471632            0.492226            0.533754   \n",
       "\n",
       "   3910.7395021722573  3911.6413100640398  3912.541178006939  ...  \\\n",
       "0            0.865628            0.984975           0.975004  ...   \n",
       "1            1.160724            1.187305           0.925614  ...   \n",
       "2            0.946960            1.062866           1.027863  ...   \n",
       "3            0.542784            0.554171           0.549082  ...   \n",
       "4            0.552509            0.561959           0.596420  ...   \n",
       "\n",
       "   7417.524757252301  7419.2311490749735  7420.942007391534  \\\n",
       "0           0.779851            0.728282           0.705656   \n",
       "1           0.730175            0.699556           0.673700   \n",
       "2           1.082616            0.865721           1.007884   \n",
       "3           1.235301            1.219081           1.153333   \n",
       "4           1.111921            1.166919           1.188617   \n",
       "\n",
       "   7422.649185348109  7424.356756038729  7426.068796308937  7427.777153676565  \\\n",
       "0           0.796199           0.861313           0.789964           0.813254   \n",
       "1           0.662072           0.653056           0.636839           0.720679   \n",
       "2           0.700454           0.734717           1.103424           1.260457   \n",
       "3           1.183530           1.282831           1.293188           1.282545   \n",
       "4           1.178303           1.149287           1.116060           1.161622   \n",
       "\n",
       "   7429.489982682914  7431.199127089972  7432.91274519583  7434.622677004906  \\\n",
       "0           0.877838           0.832707          0.821114           0.850069   \n",
       "1           0.643880           0.542382          0.667748           0.728863   \n",
       "2           1.185061           0.839313          0.923630           0.891176   \n",
       "3           1.222786           1.273009          1.326470           1.264376   \n",
       "4           1.181562           1.179871          1.175125           1.150849   \n",
       "\n",
       "   7436.333002181546  7438.047804147664  7439.758917270303  7441.474509244873  \\\n",
       "0           0.809483           0.786298           0.802253           0.844928   \n",
       "1           0.591511           0.588671           0.623791           0.604367   \n",
       "2           0.826711           0.924907           1.016810           0.959748   \n",
       "3           1.278182           1.314947           1.312632           1.293615   \n",
       "4           1.149428           1.153262           1.179789           1.169943   \n",
       "\n",
       "   7443.186410676516  7444.902793023495  7446.615483127316  7448.328567233246  \\\n",
       "0           0.827333           0.783233           0.829814           0.783733   \n",
       "1           0.717579           0.716184           0.728600           0.809191   \n",
       "2           0.999575           1.005594           0.895515           0.896164   \n",
       "3           1.296667           1.266891           1.203230           1.204343   \n",
       "4           1.165257           1.179557           1.178521           1.212370   \n",
       "\n",
       "   7450.0461353501705  7451.760008673134  7453.478368072875  \\\n",
       "0            0.794661           0.810325           0.747440   \n",
       "1            0.835630           0.755814           0.748969   \n",
       "2            0.796196           0.852573           0.926231   \n",
       "3            1.247096           1.273576           1.373208   \n",
       "4            1.192431           1.185238           1.196087   \n",
       "\n",
       "   7455.1930309764675  7456.9121820235705  7458.627634871548  7460.3434823572  \\\n",
       "0            0.753007            0.828389           0.864708         0.812884   \n",
       "1            0.790636            0.735746           0.718552         0.750787   \n",
       "2            0.981716            0.947473           0.765692         0.868425   \n",
       "3            1.427798            1.344045           1.308270         1.304600   \n",
       "4            1.176782            1.187024           1.181789         1.167352   \n",
       "\n",
       "   7462.063821087017  7463.78045906279  7465.501590351842  7467.219019181919  \\\n",
       "0           0.745643          0.751192           0.838403           0.857025   \n",
       "1           0.777957          0.748585           0.683396           0.681842   \n",
       "2           0.886143          0.760027           0.716643           0.788582   \n",
       "3           1.294358          1.332443           1.340640           1.306784   \n",
       "4           1.154860          1.143830           1.151100           1.172506   \n",
       "\n",
       "   7468.940943395341  7470.659163444065  7472.377778767054  7474.100892579042  \\\n",
       "0           0.785440           0.767616           0.743195           0.724839   \n",
       "1           0.849851           0.857925           0.773472           0.670337   \n",
       "2           0.969161           0.944397           0.834727           0.837527   \n",
       "3           1.312431           1.301884           1.303640           1.306043   \n",
       "4           1.184212           1.168895           1.170764           1.175588   \n",
       "\n",
       "   7475.820299667295  7477.544207317  7479.264406535282  7480.989108388424  \\\n",
       "0           0.805945        0.840591           0.810032           0.829138   \n",
       "1           0.628301        0.721224           0.707150           0.783355   \n",
       "2           0.748598        0.786688           0.795698           0.721892   \n",
       "3           1.291952        1.302044           1.282626           1.269255   \n",
       "4           1.164839        1.166674           1.153739           1.126513   \n",
       "\n",
       "   7482.710100101674  7484.431487726802  7486.157381097453  7487.879561765048  \\\n",
       "0           0.850290           0.763131           0.688105           0.779044   \n",
       "1           0.727580           0.692765           0.762835           0.709300   \n",
       "2           0.891034           0.984194           0.900125           0.768372   \n",
       "3           1.251645           1.265311           1.283185           1.260953   \n",
       "4           1.124752           1.141948           1.152485           1.158272   \n",
       "\n",
       "   7489.606250253956  7491.329224329366  7493.0567083028445  \\\n",
       "0           0.817667           0.815495            0.831063   \n",
       "1           0.659228           0.652220            0.759352   \n",
       "2           0.815000           0.845616            0.793658   \n",
       "3           1.278732           1.266610            1.256040   \n",
       "4           1.176106           1.230612            1.252418   \n",
       "\n",
       "   7494.7804761515945  7496.504640550872  7498.233317963899  \\\n",
       "0            0.807701           0.825111           0.779291   \n",
       "1            0.837513           0.744902           0.661489   \n",
       "2            0.875271           0.844571           0.944504   \n",
       "3            1.303732           1.329898           1.314732   \n",
       "4            1.220164           1.192720           1.185559   \n",
       "\n",
       "   7499.958276684899  7501.6877504987915  \n",
       "0           0.775595            0.852922  \n",
       "1           0.674855            0.678003  \n",
       "2           1.039832            1.056826  \n",
       "3           1.285002            1.273627  \n",
       "4           1.184189            1.151777  \n",
       "\n",
       "[5 rows x 2877 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/espectros_3k_sin_negativos.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T19:10:05.482412Z",
     "start_time": "2019-11-03T19:10:05.478485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2529, 2877)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T19:10:06.983362Z",
     "start_time": "2019-11-03T19:10:06.980410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2920, 2881)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_origen.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para luego entrenar los modelos y tener un set de test para las medidas de accuracy, dividimos el dataset en train y test (nos vale un 15% para el test). Recordemos que estamos usando un aprendizaje no supervisado y no tenemos etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T19:10:08.444050Z",
     "start_time": "2019-11-03T19:10:08.419506Z"
    }
   },
   "outputs": [],
   "source": [
    "espectros_train, espectros_test = train_test_split(data, test_size=0.15, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos seguir con el proceso, primero escalando el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T19:19:34.755171Z",
     "start_time": "2019-11-03T19:19:34.751775Z"
    }
   },
   "outputs": [],
   "source": [
    "#scaler = MinMaxScaler() # = np.array(data.apply(lambda x: (x-x.min()) / (x.max()-x.min())))\n",
    "#scaler.fit(espectros_train)\n",
    "\n",
    "# Grabamos el modelo de escalado para predicciones posteriores\n",
    "#joblib.dump(scaler, \"./scaler.save\") \n",
    "\n",
    "#espectros_train_scaled = pd.DataFrame(scaler.fit_transform(espectros_train), \n",
    "#                               columns=espectros_train.columns,\n",
    "#                               index=espectros_train.index)\n",
    "#espectros_test_scaled = pd.DataFrame(scaler.transform(espectros_test),\n",
    "#                             columns=espectros_test.columns,\n",
    "#                             index=espectros_test.index)\n",
    "\n",
    "# Esta es la versiós estandarizada de todo el dataset para comparaciones posteriores\n",
    "#espectros_scaled = pd.DataFrame(scaler.transform(data), \n",
    "#                               columns=data.columns,\n",
    "#                               index=data.index)\n",
    "#espectros_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T19:18:11.177341Z",
     "start_time": "2019-11-03T19:18:11.052639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04678941, 0.05360419, 0.05564762, ..., 0.41288072, 0.3861915 ,\n",
       "        0.44435026],\n",
       "       [0.04287027, 0.043194  , 0.04044057, ..., 0.40744456, 0.36373126,\n",
       "        0.35944993],\n",
       "       [0.06481041, 0.06412845, 0.06176416, ..., 0.24853059, 0.21913139,\n",
       "        0.21226776],\n",
       "       ...,\n",
       "       [0.00458402, 0.01198219, 0.01826583, ..., 0.47691685, 0.40893665,\n",
       "        0.39941599],\n",
       "       [0.00999957, 0.01665749, 0.01830878, ..., 0.44922983, 0.40203764,\n",
       "        0.40050846],\n",
       "       [0.01155025, 0.01636192, 0.00967703, ..., 0.48665918, 0.39929868,\n",
       "        0.41680726]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# En Tensorflow se espera que la entrada venga en formato matriz, no en DataFrame de Pandas.\n",
    "# recordemos que al perder este formato, perdemos también los nombres de los índices (las frecuencias)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler() # = np.array(data.apply(lambda x: (x-x.min()) / (x.max()-x.min())))\n",
    "#scaler.fit(espectros_train)\n",
    "\n",
    "# Grabamos el modelo de escalado para predicciones posteriores\n",
    "#joblib.dump(scaler, \"./scaler.save\") \n",
    "\n",
    "espectros_train_scaled = scaler.fit_transform(espectros_train)\n",
    "espectros_test_scaled = scaler.transform(espectros_test)\n",
    "\n",
    "# Esta es la versiós estandarizada de todo el dataset para comparaciones posteriores\n",
    "espectros_scaled = scaler.transform(data)\n",
    "espectros_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a estudiar el error que resulta al pasar los espectros por el autoencoder. En estudios previos se ha visto que este error no es el mismo en función de los tramos del espectro, por lo que vamos a dividir el mismo en cuartos y calcular el mse en cada uno de estos cuartos. \n",
    "\n",
    "Repetiremos la generación del modelo 10 veces para eliminar en parte el efecto de la aleatoriedad del autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T20:54:08.943386Z",
     "start_time": "2019-11-03T19:21:50.950225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Repetición:  0\n",
      "Train on 2149 samples, validate on 380 samples\n",
      "Epoch 1/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6987 - accuracy: 4.7002e-04 - val_loss: 0.6868 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6830 - accuracy: 4.8118e-04 - val_loss: 0.6775 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6731 - accuracy: 4.9073e-04 - val_loss: 0.6672 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6638 - accuracy: 4.9121e-04 - val_loss: 0.6596 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6570 - accuracy: 4.9089e-04 - val_loss: 0.6539 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6519 - accuracy: 4.9558e-04 - val_loss: 0.6496 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6482 - accuracy: 5.0690e-04 - val_loss: 0.6466 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6455 - accuracy: 5.1644e-04 - val_loss: 0.6444 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6436 - accuracy: 5.2210e-04 - val_loss: 0.6427 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6421 - accuracy: 5.2954e-04 - val_loss: 0.6415 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6410 - accuracy: 5.3909e-04 - val_loss: 0.6404 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6400 - accuracy: 5.4831e-04 - val_loss: 0.6395 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6392 - accuracy: 5.5558e-04 - val_loss: 0.6387 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6384 - accuracy: 5.6335e-04 - val_loss: 0.6379 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6376 - accuracy: 5.7305e-04 - val_loss: 0.6371 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6368 - accuracy: 5.8227e-04 - val_loss: 0.6363 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6361 - accuracy: 5.9101e-04 - val_loss: 0.6355 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6353 - accuracy: 5.9942e-04 - val_loss: 0.6347 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6346 - accuracy: 6.1171e-04 - val_loss: 0.6340 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6339 - accuracy: 6.2061e-04 - val_loss: 0.6333 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6332 - accuracy: 6.2982e-04 - val_loss: 0.6326 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6326 - accuracy: 6.3565e-04 - val_loss: 0.6320 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6320 - accuracy: 6.4390e-04 - val_loss: 0.6314 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6315 - accuracy: 6.4875e-04 - val_loss: 0.6308 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6309 - accuracy: 6.5829e-04 - val_loss: 0.6303 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6305 - accuracy: 6.6444e-04 - val_loss: 0.6298 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6300 - accuracy: 6.7042e-04 - val_loss: 0.6294 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6296 - accuracy: 6.7576e-04 - val_loss: 0.6290 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6292 - accuracy: 6.7819e-04 - val_loss: 0.6286 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6289 - accuracy: 6.8174e-04 - val_loss: 0.6282 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6286 - accuracy: 6.8514e-04 - val_loss: 0.6279 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6283 - accuracy: 6.8870e-04 - val_loss: 0.6277 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6281 - accuracy: 6.8951e-04 - val_loss: 0.6274 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6278 - accuracy: 6.8999e-04 - val_loss: 0.6272 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6276 - accuracy: 6.9274e-04 - val_loss: 0.6270 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6275 - accuracy: 6.9452e-04 - val_loss: 0.6268 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6273 - accuracy: 6.9662e-04 - val_loss: 0.6266 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6271 - accuracy: 6.9727e-04 - val_loss: 0.6265 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6270 - accuracy: 6.9776e-04 - val_loss: 0.6263 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6269 - accuracy: 7.0018e-04 - val_loss: 0.6262 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6268 - accuracy: 7.0131e-04 - val_loss: 0.6261 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6267 - accuracy: 7.0374e-04 - val_loss: 0.6260 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6266 - accuracy: 7.0503e-04 - val_loss: 0.6259 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6265 - accuracy: 7.0568e-04 - val_loss: 0.6258 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6264 - accuracy: 7.0601e-04 - val_loss: 0.6257 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6263 - accuracy: 7.0617e-04 - val_loss: 0.6256 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6263 - accuracy: 7.0730e-04 - val_loss: 0.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6262 - accuracy: 7.0698e-04 - val_loss: 0.6254 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6261 - accuracy: 7.0730e-04 - val_loss: 0.6254 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6261 - accuracy: 7.0778e-04 - val_loss: 0.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6260 - accuracy: 7.0746e-04 - val_loss: 0.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6260 - accuracy: 7.0778e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6259 - accuracy: 7.0811e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6259 - accuracy: 7.0795e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6259 - accuracy: 7.0843e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.0843e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6258 - accuracy: 7.0859e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6258 - accuracy: 7.1005e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.1005e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.1037e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.1021e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.1021e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6256 - accuracy: 7.1037e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1053e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1086e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1053e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1070e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1070e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6255 - accuracy: 7.1053e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6255 - accuracy: 7.1086e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6255 - accuracy: 7.1118e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1086e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1134e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1053e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1086e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1021e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1150e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1086e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1167e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1102e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1167e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1102e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1102e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1150e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1134e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1199e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1118e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1167e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1167e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1215e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1167e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1118e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1183e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1167e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6253 - accuracy: 7.1296e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1118e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6253 - accuracy: 7.1231e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1183e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1167e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1150e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1215e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1199e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1167e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6252 - accuracy: 7.1231e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1215e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1215e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1134e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1167e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1167e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1248e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1167e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1248e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1150e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1231e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1167e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1118e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6252 - accuracy: 7.1215e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1118e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1183e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1167e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1134e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1231e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1199e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1167e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1215e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "*** Repetición:  1\n",
      "Train on 2149 samples, validate on 380 samples\n",
      "Epoch 1/125\n",
      "2149/2149 [==============================] - 6s 3ms/sample - loss: 0.6978 - accuracy: 4.7811e-04 - val_loss: 0.6865 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6824 - accuracy: 4.8442e-04 - val_loss: 0.6762 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6723 - accuracy: 4.9703e-04 - val_loss: 0.6670 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6637 - accuracy: 5.0399e-04 - val_loss: 0.6595 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6569 - accuracy: 5.0496e-04 - val_loss: 0.6537 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6518 - accuracy: 5.1078e-04 - val_loss: 0.6495 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6480 - accuracy: 5.1499e-04 - val_loss: 0.6464 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6454 - accuracy: 5.2033e-04 - val_loss: 0.6443 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6435 - accuracy: 5.2372e-04 - val_loss: 0.6427 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6421 - accuracy: 5.3116e-04 - val_loss: 0.6414 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6409 - accuracy: 5.3860e-04 - val_loss: 0.6404 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6400 - accuracy: 5.4766e-04 - val_loss: 0.6395 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6392 - accuracy: 5.5720e-04 - val_loss: 0.6387 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6384 - accuracy: 5.6432e-04 - val_loss: 0.6380 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6376 - accuracy: 5.7467e-04 - val_loss: 0.6372 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6369 - accuracy: 5.8729e-04 - val_loss: 0.6364 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6362 - accuracy: 5.9877e-04 - val_loss: 0.6357 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6354 - accuracy: 6.0621e-04 - val_loss: 0.6349 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6347 - accuracy: 6.1624e-04 - val_loss: 0.6342 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6341 - accuracy: 6.2465e-04 - val_loss: 0.6335 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6334 - accuracy: 6.3209e-04 - val_loss: 0.6328 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6328 - accuracy: 6.3937e-04 - val_loss: 0.6322 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6322 - accuracy: 6.4503e-04 - val_loss: 0.6316 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6316 - accuracy: 6.5328e-04 - val_loss: 0.6310 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6311 - accuracy: 6.5797e-04 - val_loss: 0.6305 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6306 - accuracy: 6.6395e-04 - val_loss: 0.6300 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6302 - accuracy: 6.7172e-04 - val_loss: 0.6296 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6298 - accuracy: 6.7608e-04 - val_loss: 0.6292 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6294 - accuracy: 6.7964e-04 - val_loss: 0.6288 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6291 - accuracy: 6.8368e-04 - val_loss: 0.6284 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6287 - accuracy: 6.8773e-04 - val_loss: 0.6281 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6285 - accuracy: 6.8918e-04 - val_loss: 0.6278 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6282 - accuracy: 6.9064e-04 - val_loss: 0.6276 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6280 - accuracy: 6.9274e-04 - val_loss: 0.6273 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6277 - accuracy: 6.9307e-04 - val_loss: 0.6271 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6276 - accuracy: 6.9468e-04 - val_loss: 0.6269 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6274 - accuracy: 6.9614e-04 - val_loss: 0.6267 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6272 - accuracy: 6.9776e-04 - val_loss: 0.6266 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6271 - accuracy: 6.9937e-04 - val_loss: 0.6265 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6269 - accuracy: 7.0067e-04 - val_loss: 0.6263 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6268 - accuracy: 7.0212e-04 - val_loss: 0.6262 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6267 - accuracy: 7.0342e-04 - val_loss: 0.6261 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6266 - accuracy: 7.0423e-04 - val_loss: 0.6259 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6265 - accuracy: 7.0342e-04 - val_loss: 0.6258 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6264 - accuracy: 7.0455e-04 - val_loss: 0.6257 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6264 - accuracy: 7.0536e-04 - val_loss: 0.6257 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6263 - accuracy: 7.0617e-04 - val_loss: 0.6256 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6262 - accuracy: 7.0762e-04 - val_loss: 0.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6262 - accuracy: 7.0762e-04 - val_loss: 0.6254 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6261 - accuracy: 7.0827e-04 - val_loss: 0.6254 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6261 - accuracy: 7.0811e-04 - val_loss: 0.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6260 - accuracy: 7.0795e-04 - val_loss: 0.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6260 - accuracy: 7.0892e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6259 - accuracy: 7.0811e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6259 - accuracy: 7.0827e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6259 - accuracy: 7.0940e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6258 - accuracy: 7.0956e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6258 - accuracy: 7.1070e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6258 - accuracy: 7.1086e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6257 - accuracy: 7.1102e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.1102e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.1150e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.1086e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.1183e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6256 - accuracy: 7.1150e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1231e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1183e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1183e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1248e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1264e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6255 - accuracy: 7.1231e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6255 - accuracy: 7.1312e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1361e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1345e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1409e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1393e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1345e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1361e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1409e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1425e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1361e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1425e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6254 - accuracy: 7.1458e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1474e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1458e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1490e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1425e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1490e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1458e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1442e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1506e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1506e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1506e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1490e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1506e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1539e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1539e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1571e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1571e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1587e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1474e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1571e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1603e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6252 - accuracy: 7.1587e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1522e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6252 - accuracy: 7.1571e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1522e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1555e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1603e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1539e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1587e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1571e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1571e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1571e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1636e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1733e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1636e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1587e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1636e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1603e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1652e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1684e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1700e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1684e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1571e-04 - val_loss: 0.6240 - val_accuracy: 0.0000e+00\n",
      "*** Repetición:  2\n",
      "Train on 2149 samples, validate on 380 samples\n",
      "Epoch 1/125\n",
      "2149/2149 [==============================] - 7s 3ms/sample - loss: 0.6999 - accuracy: 4.6986e-04 - val_loss: 0.6918 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6853 - accuracy: 4.8280e-04 - val_loss: 0.6786 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6748 - accuracy: 4.8636e-04 - val_loss: 0.6696 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6663 - accuracy: 4.9590e-04 - val_loss: 0.6620 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6593 - accuracy: 4.9590e-04 - val_loss: 0.6559 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6538 - accuracy: 4.9865e-04 - val_loss: 0.6512 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6496 - accuracy: 5.0609e-04 - val_loss: 0.6477 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6465 - accuracy: 5.0868e-04 - val_loss: 0.6452 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6443 - accuracy: 5.1741e-04 - val_loss: 0.6433 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6426 - accuracy: 5.2485e-04 - val_loss: 0.6419 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6414 - accuracy: 5.3440e-04 - val_loss: 0.6408 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6403 - accuracy: 5.4135e-04 - val_loss: 0.6398 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6394 - accuracy: 5.4992e-04 - val_loss: 0.6390 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6386 - accuracy: 5.5947e-04 - val_loss: 0.6381 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6378 - accuracy: 5.6982e-04 - val_loss: 0.6373 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6370 - accuracy: 5.7791e-04 - val_loss: 0.6366 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6363 - accuracy: 5.8729e-04 - val_loss: 0.6358 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6355 - accuracy: 5.9570e-04 - val_loss: 0.6350 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6348 - accuracy: 6.0540e-04 - val_loss: 0.6343 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6341 - accuracy: 6.1397e-04 - val_loss: 0.6336 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6335 - accuracy: 6.2546e-04 - val_loss: 0.6329 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6328 - accuracy: 6.3387e-04 - val_loss: 0.6323 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6322 - accuracy: 6.4131e-04 - val_loss: 0.6317 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6317 - accuracy: 6.4794e-04 - val_loss: 0.6311 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6311 - accuracy: 6.5570e-04 - val_loss: 0.6306 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6306 - accuracy: 6.6153e-04 - val_loss: 0.6301 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6302 - accuracy: 6.6525e-04 - val_loss: 0.6296 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6298 - accuracy: 6.6961e-04 - val_loss: 0.6292 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6294 - accuracy: 6.7447e-04 - val_loss: 0.6288 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6291 - accuracy: 6.7754e-04 - val_loss: 0.6285 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6287 - accuracy: 6.8223e-04 - val_loss: 0.6281 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6285 - accuracy: 6.8546e-04 - val_loss: 0.6279 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6282 - accuracy: 6.8821e-04 - val_loss: 0.6276 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6280 - accuracy: 6.8902e-04 - val_loss: 0.6274 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6278 - accuracy: 6.9080e-04 - val_loss: 0.6272 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6276 - accuracy: 6.9258e-04 - val_loss: 0.6270 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6274 - accuracy: 6.9371e-04 - val_loss: 0.6268 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6272 - accuracy: 6.9582e-04 - val_loss: 0.6266 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6271 - accuracy: 6.9646e-04 - val_loss: 0.6265 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6270 - accuracy: 6.9743e-04 - val_loss: 0.6263 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6269 - accuracy: 6.9921e-04 - val_loss: 0.6262 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6268 - accuracy: 7.0034e-04 - val_loss: 0.6261 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6267 - accuracy: 7.0018e-04 - val_loss: 0.6260 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6266 - accuracy: 7.0115e-04 - val_loss: 0.6259 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6265 - accuracy: 7.0245e-04 - val_loss: 0.6258 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6264 - accuracy: 7.0229e-04 - val_loss: 0.6257 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6263 - accuracy: 7.0293e-04 - val_loss: 0.6256 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6263 - accuracy: 7.0326e-04 - val_loss: 0.6256 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6262 - accuracy: 7.0439e-04 - val_loss: 0.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6262 - accuracy: 7.0390e-04 - val_loss: 0.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6261 - accuracy: 7.0552e-04 - val_loss: 0.6254 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6261 - accuracy: 7.0520e-04 - val_loss: 0.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6260 - accuracy: 7.0584e-04 - val_loss: 0.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6260 - accuracy: 7.0601e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6259 - accuracy: 7.0649e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6259 - accuracy: 7.0649e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6259 - accuracy: 7.0649e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.0730e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.0762e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.0778e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.0795e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.0859e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6257 - accuracy: 7.0811e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6257 - accuracy: 7.0875e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6257 - accuracy: 7.0940e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.0940e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6256 - accuracy: 7.0940e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.0892e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6256 - accuracy: 7.0940e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.0908e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6256 - accuracy: 7.0973e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.0973e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6255 - accuracy: 7.0956e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1005e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6255 - accuracy: 7.0989e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1053e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1021e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1021e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1021e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1005e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6254 - accuracy: 7.1102e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1102e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1070e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1086e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1118e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6254 - accuracy: 7.1183e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1118e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1086e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1150e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1150e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1134e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1167e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1215e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1183e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1183e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1183e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1167e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1215e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1183e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1248e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1215e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1248e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1280e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1167e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1199e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1247e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1231e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1215e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1215e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1296e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1231e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1231e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1264e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1231e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1296e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1248e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1296e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1150e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1199e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1199e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6252 - accuracy: 7.1248e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1248e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6251 - accuracy: 7.1264e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1231e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1199e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "*** Repetición:  3\n",
      "Train on 2149 samples, validate on 380 samples\n",
      "Epoch 1/125\n",
      "2149/2149 [==============================] - 7s 3ms/sample - loss: 0.6985 - accuracy: 4.7649e-04 - val_loss: 0.6873 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6838 - accuracy: 4.8636e-04 - val_loss: 0.6770 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6727 - accuracy: 4.9364e-04 - val_loss: 0.6674 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6641 - accuracy: 5.0043e-04 - val_loss: 0.6599 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6573 - accuracy: 5.0059e-04 - val_loss: 0.6541 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6521 - accuracy: 5.0108e-04 - val_loss: 0.6497 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6483 - accuracy: 5.0561e-04 - val_loss: 0.6466 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6456 - accuracy: 5.1014e-04 - val_loss: 0.6444 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6437 - accuracy: 5.1984e-04 - val_loss: 0.6428 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6422 - accuracy: 5.2615e-04 - val_loss: 0.6416 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6411 - accuracy: 5.3585e-04 - val_loss: 0.6406 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6402 - accuracy: 5.4442e-04 - val_loss: 0.6397 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6394 - accuracy: 5.5203e-04 - val_loss: 0.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6386 - accuracy: 5.6383e-04 - val_loss: 0.6381 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6378 - accuracy: 5.7629e-04 - val_loss: 0.6373 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6371 - accuracy: 5.8680e-04 - val_loss: 0.6366 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6363 - accuracy: 5.9845e-04 - val_loss: 0.6358 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6356 - accuracy: 6.0524e-04 - val_loss: 0.6350 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6349 - accuracy: 6.1284e-04 - val_loss: 0.6343 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6342 - accuracy: 6.2303e-04 - val_loss: 0.6336 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6335 - accuracy: 6.2918e-04 - val_loss: 0.6329 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6329 - accuracy: 6.3613e-04 - val_loss: 0.6323 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6322 - accuracy: 6.4503e-04 - val_loss: 0.6316 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6317 - accuracy: 6.5263e-04 - val_loss: 0.6311 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6312 - accuracy: 6.5861e-04 - val_loss: 0.6305 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6307 - accuracy: 6.6266e-04 - val_loss: 0.6300 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6302 - accuracy: 6.6751e-04 - val_loss: 0.6296 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6298 - accuracy: 6.7236e-04 - val_loss: 0.6292 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6294 - accuracy: 6.7624e-04 - val_loss: 0.6288 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6291 - accuracy: 6.8077e-04 - val_loss: 0.6284 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6287 - accuracy: 6.8401e-04 - val_loss: 0.6281 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6284 - accuracy: 6.8708e-04 - val_loss: 0.6278 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6282 - accuracy: 6.9015e-04 - val_loss: 0.6275 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6279 - accuracy: 6.9258e-04 - val_loss: 0.6273 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6277 - accuracy: 6.9307e-04 - val_loss: 0.6271 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6275 - accuracy: 6.9468e-04 - val_loss: 0.6269 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6273 - accuracy: 6.9662e-04 - val_loss: 0.6267 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6272 - accuracy: 6.9792e-04 - val_loss: 0.6265 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6270 - accuracy: 7.0002e-04 - val_loss: 0.6264 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6269 - accuracy: 7.0002e-04 - val_loss: 0.6262 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6268 - accuracy: 7.0164e-04 - val_loss: 0.6261 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6267 - accuracy: 7.0212e-04 - val_loss: 0.6260 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6266 - accuracy: 7.0245e-04 - val_loss: 0.6259 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6265 - accuracy: 7.0358e-04 - val_loss: 0.6258 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6264 - accuracy: 7.0423e-04 - val_loss: 0.6257 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6263 - accuracy: 7.0536e-04 - val_loss: 0.6256 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6263 - accuracy: 7.0633e-04 - val_loss: 0.6256 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6262 - accuracy: 7.0633e-04 - val_loss: 0.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6261 - accuracy: 7.0665e-04 - val_loss: 0.6254 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6261 - accuracy: 7.0827e-04 - val_loss: 0.6254 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6260 - accuracy: 7.0875e-04 - val_loss: 0.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6260 - accuracy: 7.0924e-04 - val_loss: 0.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6260 - accuracy: 7.0973e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6259 - accuracy: 7.0956e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6259 - accuracy: 7.0973e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.1053e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.1053e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.1102e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.1134e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.1102e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.1118e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.1183e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.1118e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6256 - accuracy: 7.1134e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6256 - accuracy: 7.1118e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1134e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1150e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1086e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1183e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1102e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1134e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1134e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1150e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1167e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1231e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6255 - accuracy: 7.1248e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1183e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1231e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1199e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1199e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1248e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1264e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1280e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1248e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1215e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1248e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1296e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6253 - accuracy: 7.1280e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1328e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1312e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1296e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1280e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1377e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1409e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1361e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6253 - accuracy: 7.1409e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1377e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1377e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1425e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1361e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1361e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1506e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1458e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1458e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1442e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1458e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1490e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1490e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1571e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1490e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1539e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1571e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1539e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1522e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1587e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1620e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1539e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1555e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1587e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1587e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1522e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1539e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6251 - accuracy: 7.1603e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6251 - accuracy: 7.1555e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1620e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "*** Repetición:  4\n",
      "Train on 2149 samples, validate on 380 samples\n",
      "Epoch 1/125\n",
      "2149/2149 [==============================] - 7s 3ms/sample - loss: 0.7013 - accuracy: 4.7520e-04 - val_loss: 0.6898 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6852 - accuracy: 4.8976e-04 - val_loss: 0.6781 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6740 - accuracy: 4.9768e-04 - val_loss: 0.6687 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6653 - accuracy: 5.0512e-04 - val_loss: 0.6610 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6582 - accuracy: 5.0884e-04 - val_loss: 0.6549 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6529 - accuracy: 5.1175e-04 - val_loss: 0.6503 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6488 - accuracy: 5.1515e-04 - val_loss: 0.6470 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6459 - accuracy: 5.1774e-04 - val_loss: 0.6446 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6438 - accuracy: 5.2437e-04 - val_loss: 0.6428 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6421 - accuracy: 5.2987e-04 - val_loss: 0.6414 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6408 - accuracy: 5.3957e-04 - val_loss: 0.6402 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6398 - accuracy: 5.4879e-04 - val_loss: 0.6392 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6388 - accuracy: 5.6011e-04 - val_loss: 0.6383 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6379 - accuracy: 5.7047e-04 - val_loss: 0.6374 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6371 - accuracy: 5.8438e-04 - val_loss: 0.6365 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6363 - accuracy: 5.9376e-04 - val_loss: 0.6357 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6355 - accuracy: 6.0136e-04 - val_loss: 0.6349 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6347 - accuracy: 6.1268e-04 - val_loss: 0.6342 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6340 - accuracy: 6.2416e-04 - val_loss: 0.6334 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6333 - accuracy: 6.3177e-04 - val_loss: 0.6327 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6327 - accuracy: 6.3937e-04 - val_loss: 0.6321 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6321 - accuracy: 6.4713e-04 - val_loss: 0.6314 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6315 - accuracy: 6.5425e-04 - val_loss: 0.6309 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6310 - accuracy: 6.5942e-04 - val_loss: 0.6303 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6305 - accuracy: 6.6460e-04 - val_loss: 0.6298 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6300 - accuracy: 6.6945e-04 - val_loss: 0.6294 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6296 - accuracy: 6.7414e-04 - val_loss: 0.6290 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6292 - accuracy: 6.7867e-04 - val_loss: 0.6286 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6289 - accuracy: 6.8077e-04 - val_loss: 0.6282 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6286 - accuracy: 6.8482e-04 - val_loss: 0.6279 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6283 - accuracy: 6.8741e-04 - val_loss: 0.6276 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6280 - accuracy: 6.9015e-04 - val_loss: 0.6274 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6278 - accuracy: 6.9290e-04 - val_loss: 0.6272 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6276 - accuracy: 6.9436e-04 - val_loss: 0.6270 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6274 - accuracy: 6.9468e-04 - val_loss: 0.6268 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6273 - accuracy: 6.9695e-04 - val_loss: 0.6266 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6271 - accuracy: 6.9808e-04 - val_loss: 0.6264 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6270 - accuracy: 6.9937e-04 - val_loss: 0.6263 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6268 - accuracy: 7.0083e-04 - val_loss: 0.6262 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6267 - accuracy: 7.0245e-04 - val_loss: 0.6261 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6266 - accuracy: 7.0180e-04 - val_loss: 0.6259 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6265 - accuracy: 7.0229e-04 - val_loss: 0.6259 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6265 - accuracy: 7.0261e-04 - val_loss: 0.6258 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6264 - accuracy: 7.0309e-04 - val_loss: 0.6257 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6263 - accuracy: 7.0390e-04 - val_loss: 0.6256 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6262 - accuracy: 7.0406e-04 - val_loss: 0.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6262 - accuracy: 7.0471e-04 - val_loss: 0.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6261 - accuracy: 7.0568e-04 - val_loss: 0.6254 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6261 - accuracy: 7.0520e-04 - val_loss: 0.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6260 - accuracy: 7.0698e-04 - val_loss: 0.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6260 - accuracy: 7.0746e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6259 - accuracy: 7.0746e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6259 - accuracy: 7.0827e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6259 - accuracy: 7.0795e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.0827e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.0811e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.0746e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.0859e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.0859e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6257 - accuracy: 7.0908e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6257 - accuracy: 7.0940e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.0956e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1021e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.0989e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6256 - accuracy: 7.0973e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1037e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1005e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1021e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1183e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1167e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1118e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6255 - accuracy: 7.1199e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1199e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1167e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1231e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1215e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6254 - accuracy: 7.1312e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1280e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6254 - accuracy: 7.1280e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1231e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1296e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1280e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1345e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1312e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1361e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1345e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1345e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6253 - accuracy: 7.1377e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1377e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6253 - accuracy: 7.1312e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1409e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1361e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1409e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1409e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1458e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1393e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1442e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1409e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1409e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1442e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1458e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1555e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1458e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1490e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1522e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1506e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1458e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1474e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1555e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1506e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1555e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1587e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6252 - accuracy: 7.1506e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1571e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1603e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1555e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1506e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1539e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1506e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1539e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1539e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1603e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1571e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1571e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6252 - accuracy: 7.1620e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "*** Repetición:  5\n",
      "Train on 2149 samples, validate on 380 samples\n",
      "Epoch 1/125\n",
      "2149/2149 [==============================] - 7s 3ms/sample - loss: 0.6992 - accuracy: 4.7488e-04 - val_loss: 0.6891 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6850 - accuracy: 4.8507e-04 - val_loss: 0.6780 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6739 - accuracy: 4.9623e-04 - val_loss: 0.6684 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6651 - accuracy: 5.0027e-04 - val_loss: 0.6607 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6581 - accuracy: 5.0544e-04 - val_loss: 0.6547 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6528 - accuracy: 5.0561e-04 - val_loss: 0.6503 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6488 - accuracy: 5.1127e-04 - val_loss: 0.6470 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6460 - accuracy: 5.1272e-04 - val_loss: 0.6447 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6439 - accuracy: 5.1741e-04 - val_loss: 0.6430 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6424 - accuracy: 5.2582e-04 - val_loss: 0.6417 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6412 - accuracy: 5.3278e-04 - val_loss: 0.6406 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6402 - accuracy: 5.4216e-04 - val_loss: 0.6397 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6394 - accuracy: 5.5267e-04 - val_loss: 0.6388 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6385 - accuracy: 5.6448e-04 - val_loss: 0.6380 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6377 - accuracy: 5.7419e-04 - val_loss: 0.6372 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6370 - accuracy: 5.8535e-04 - val_loss: 0.6364 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6362 - accuracy: 5.9586e-04 - val_loss: 0.6356 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6355 - accuracy: 6.0670e-04 - val_loss: 0.6349 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6347 - accuracy: 6.1608e-04 - val_loss: 0.6341 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6340 - accuracy: 6.2610e-04 - val_loss: 0.6334 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6333 - accuracy: 6.3274e-04 - val_loss: 0.6327 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6327 - accuracy: 6.4066e-04 - val_loss: 0.6321 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6321 - accuracy: 6.4859e-04 - val_loss: 0.6314 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6315 - accuracy: 6.5651e-04 - val_loss: 0.6309 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6310 - accuracy: 6.6072e-04 - val_loss: 0.6304 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6305 - accuracy: 6.6589e-04 - val_loss: 0.6299 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6301 - accuracy: 6.7042e-04 - val_loss: 0.6294 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6296 - accuracy: 6.7447e-04 - val_loss: 0.6290 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6293 - accuracy: 6.7819e-04 - val_loss: 0.6286 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6289 - accuracy: 6.8207e-04 - val_loss: 0.6283 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6286 - accuracy: 6.8449e-04 - val_loss: 0.6279 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6283 - accuracy: 6.8692e-04 - val_loss: 0.6277 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6281 - accuracy: 6.9048e-04 - val_loss: 0.6274 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6279 - accuracy: 6.9371e-04 - val_loss: 0.6272 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6277 - accuracy: 6.9582e-04 - val_loss: 0.6270 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6275 - accuracy: 6.9695e-04 - val_loss: 0.6268 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6273 - accuracy: 6.9857e-04 - val_loss: 0.6266 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6271 - accuracy: 6.9970e-04 - val_loss: 0.6264 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6270 - accuracy: 7.0099e-04 - val_loss: 0.6263 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6269 - accuracy: 7.0212e-04 - val_loss: 0.6262 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6268 - accuracy: 7.0358e-04 - val_loss: 0.6260 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6266 - accuracy: 7.0245e-04 - val_loss: 0.6259 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6265 - accuracy: 7.0358e-04 - val_loss: 0.6258 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6265 - accuracy: 7.0455e-04 - val_loss: 0.6257 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6264 - accuracy: 7.0552e-04 - val_loss: 0.6256 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6263 - accuracy: 7.0503e-04 - val_loss: 0.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6262 - accuracy: 7.0520e-04 - val_loss: 0.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6262 - accuracy: 7.0552e-04 - val_loss: 0.6254 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6261 - accuracy: 7.0698e-04 - val_loss: 0.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6261 - accuracy: 7.0730e-04 - val_loss: 0.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6260 - accuracy: 7.0714e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6260 - accuracy: 7.0681e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6259 - accuracy: 7.0795e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6259 - accuracy: 7.0795e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6259 - accuracy: 7.0795e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6258 - accuracy: 7.0875e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6258 - accuracy: 7.0859e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.0876e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.0892e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.0827e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6257 - accuracy: 7.0908e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.0892e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.0859e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.0875e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6256 - accuracy: 7.0940e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.0859e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6256 - accuracy: 7.0924e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6255 - accuracy: 7.0908e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6255 - accuracy: 7.0892e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6255 - accuracy: 7.0956e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6255 - accuracy: 7.0956e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6255 - accuracy: 7.0859e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6255 - accuracy: 7.0940e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6255 - accuracy: 7.0924e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.0973e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.0956e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1053e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1005e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1021e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.0989e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1021e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6254 - accuracy: 7.1053e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1086e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1070e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1053e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1070e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6253 - accuracy: 7.1118e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1086e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6253 - accuracy: 7.1118e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1150e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6253 - accuracy: 7.1070e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1021e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1070e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1102e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1183e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1118e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1070e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1086e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1150e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1118e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1167e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1118e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1102e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1134e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1053e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1167e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1167e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1021e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1118e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1199e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1070e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6252 - accuracy: 7.1037e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1134e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1150e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1199e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1183e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1150e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1231e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1183e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6251 - accuracy: 7.1231e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1183e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1215e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1328e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1328e-04 - val_loss: 0.6240 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6251 - accuracy: 7.1296e-04 - val_loss: 0.6240 - val_accuracy: 0.0000e+00\n",
      "*** Repetición:  6\n",
      "Train on 2149 samples, validate on 380 samples\n",
      "Epoch 1/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.7010 - accuracy: 4.7196e-04 - val_loss: 0.6890 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6862 - accuracy: 4.8393e-04 - val_loss: 0.6805 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6763 - accuracy: 4.9493e-04 - val_loss: 0.6707 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6673 - accuracy: 5.0156e-04 - val_loss: 0.6628 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6600 - accuracy: 4.9995e-04 - val_loss: 0.6564 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6542 - accuracy: 5.0221e-04 - val_loss: 0.6515 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6498 - accuracy: 5.0512e-04 - val_loss: 0.6479 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6467 - accuracy: 5.0868e-04 - val_loss: 0.6453 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6444 - accuracy: 5.1838e-04 - val_loss: 0.6434 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6428 - accuracy: 5.2679e-04 - val_loss: 0.6420 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6415 - accuracy: 5.3294e-04 - val_loss: 0.6409 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6404 - accuracy: 5.4313e-04 - val_loss: 0.6400 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6396 - accuracy: 5.5364e-04 - val_loss: 0.6391 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6387 - accuracy: 5.6076e-04 - val_loss: 0.6383 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6380 - accuracy: 5.7257e-04 - val_loss: 0.6375 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6372 - accuracy: 5.8260e-04 - val_loss: 0.6367 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6365 - accuracy: 5.9068e-04 - val_loss: 0.6359 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6357 - accuracy: 5.9990e-04 - val_loss: 0.6352 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6350 - accuracy: 6.0847e-04 - val_loss: 0.6345 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6343 - accuracy: 6.1656e-04 - val_loss: 0.6338 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6337 - accuracy: 6.2368e-04 - val_loss: 0.6331 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6331 - accuracy: 6.3371e-04 - val_loss: 0.6324 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6325 - accuracy: 6.3985e-04 - val_loss: 0.6318 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6319 - accuracy: 6.4551e-04 - val_loss: 0.6312 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6313 - accuracy: 6.5182e-04 - val_loss: 0.6307 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6308 - accuracy: 6.5700e-04 - val_loss: 0.6302 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6304 - accuracy: 6.6411e-04 - val_loss: 0.6297 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6299 - accuracy: 6.6945e-04 - val_loss: 0.6293 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6295 - accuracy: 6.7333e-04 - val_loss: 0.6289 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6292 - accuracy: 6.7770e-04 - val_loss: 0.6285 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6288 - accuracy: 6.8158e-04 - val_loss: 0.6282 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6286 - accuracy: 6.8449e-04 - val_loss: 0.6279 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6283 - accuracy: 6.8724e-04 - val_loss: 0.6276 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6280 - accuracy: 6.9064e-04 - val_loss: 0.6274 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6278 - accuracy: 6.9274e-04 - val_loss: 0.6271 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6276 - accuracy: 6.9468e-04 - val_loss: 0.6269 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6274 - accuracy: 6.9662e-04 - val_loss: 0.6267 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6273 - accuracy: 6.9743e-04 - val_loss: 0.6265 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6271 - accuracy: 6.9986e-04 - val_loss: 0.6264 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6270 - accuracy: 6.9970e-04 - val_loss: 0.6263 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6268 - accuracy: 7.0099e-04 - val_loss: 0.6261 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6267 - accuracy: 7.0180e-04 - val_loss: 0.6260 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6266 - accuracy: 7.0326e-04 - val_loss: 0.6259 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6265 - accuracy: 7.0406e-04 - val_loss: 0.6258 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6265 - accuracy: 7.0342e-04 - val_loss: 0.6257 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6264 - accuracy: 7.0358e-04 - val_loss: 0.6256 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6263 - accuracy: 7.0503e-04 - val_loss: 0.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6262 - accuracy: 7.0439e-04 - val_loss: 0.6254 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6262 - accuracy: 7.0601e-04 - val_loss: 0.6254 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6261 - accuracy: 7.0649e-04 - val_loss: 0.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6261 - accuracy: 7.0681e-04 - val_loss: 0.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6260 - accuracy: 7.0778e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6260 - accuracy: 7.0698e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6259 - accuracy: 7.0730e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6259 - accuracy: 7.0730e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6259 - accuracy: 7.0778e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6258 - accuracy: 7.0811e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6258 - accuracy: 7.0843e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6258 - accuracy: 7.0811e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6257 - accuracy: 7.0762e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.0795e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.0746e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.0843e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.0843e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.0827e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.0892e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6256 - accuracy: 7.0778e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6256 - accuracy: 7.0827e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6256 - accuracy: 7.0811e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6255 - accuracy: 7.0827e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6255 - accuracy: 7.0827e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.0875e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.0908e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.0843e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.0924e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.0908e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.0956e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.0956e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.0989e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.0940e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.0924e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1021e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1005e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.0973e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1053e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1053e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1053e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.0989e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1021e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1070e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1021e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1021e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1102e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1037e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1037e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1070e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1037e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1037e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1037e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1037e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1053e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1021e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6252 - accuracy: 7.1037e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1118e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1086e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1086e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1086e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1070e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1037e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1118e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1053e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1102e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1053e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1086e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6252 - accuracy: 7.1053e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1037e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1053e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1070e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1102e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1070e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1086e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6251 - accuracy: 7.1053e-04 - val_loss: 0.6240 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6251 - accuracy: 7.1070e-04 - val_loss: 0.6240 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1070e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6251 - accuracy: 7.1086e-04 - val_loss: 0.6240 - val_accuracy: 0.0000e+00\n",
      "*** Repetición:  7\n",
      "Train on 2149 samples, validate on 380 samples\n",
      "Epoch 1/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6989 - accuracy: 4.7213e-04 - val_loss: 0.6880 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6832 - accuracy: 4.8199e-04 - val_loss: 0.6765 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6721 - accuracy: 4.9283e-04 - val_loss: 0.6666 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6633 - accuracy: 5.0043e-04 - val_loss: 0.6591 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6565 - accuracy: 5.0447e-04 - val_loss: 0.6534 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6514 - accuracy: 5.0722e-04 - val_loss: 0.6491 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6477 - accuracy: 5.1499e-04 - val_loss: 0.6461 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6451 - accuracy: 5.1790e-04 - val_loss: 0.6440 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6432 - accuracy: 5.2566e-04 - val_loss: 0.6424 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6418 - accuracy: 5.3100e-04 - val_loss: 0.6412 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6407 - accuracy: 5.4168e-04 - val_loss: 0.6402 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6398 - accuracy: 5.5025e-04 - val_loss: 0.6393 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6389 - accuracy: 5.5494e-04 - val_loss: 0.6385 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6382 - accuracy: 5.6626e-04 - val_loss: 0.6376 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6374 - accuracy: 5.7645e-04 - val_loss: 0.6369 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6367 - accuracy: 5.8874e-04 - val_loss: 0.6361 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6359 - accuracy: 5.9877e-04 - val_loss: 0.6354 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6352 - accuracy: 6.0831e-04 - val_loss: 0.6346 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6345 - accuracy: 6.1656e-04 - val_loss: 0.6339 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6338 - accuracy: 6.2497e-04 - val_loss: 0.6332 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6332 - accuracy: 6.3225e-04 - val_loss: 0.6326 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6326 - accuracy: 6.4050e-04 - val_loss: 0.6319 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6320 - accuracy: 6.5020e-04 - val_loss: 0.6313 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6314 - accuracy: 6.5667e-04 - val_loss: 0.6308 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6309 - accuracy: 6.6331e-04 - val_loss: 0.6303 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6304 - accuracy: 6.6703e-04 - val_loss: 0.6298 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6300 - accuracy: 6.7252e-04 - val_loss: 0.6293 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6296 - accuracy: 6.7786e-04 - val_loss: 0.6289 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6292 - accuracy: 6.8126e-04 - val_loss: 0.6285 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6289 - accuracy: 6.8417e-04 - val_loss: 0.6282 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6286 - accuracy: 6.8708e-04 - val_loss: 0.6279 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6283 - accuracy: 6.8935e-04 - val_loss: 0.6276 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6280 - accuracy: 6.9080e-04 - val_loss: 0.6274 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6278 - accuracy: 6.9323e-04 - val_loss: 0.6271 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6276 - accuracy: 6.9307e-04 - val_loss: 0.6269 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6274 - accuracy: 6.9468e-04 - val_loss: 0.6267 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6273 - accuracy: 6.9533e-04 - val_loss: 0.6266 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6271 - accuracy: 6.9630e-04 - val_loss: 0.6264 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6270 - accuracy: 6.9776e-04 - val_loss: 0.6263 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6268 - accuracy: 6.9954e-04 - val_loss: 0.6261 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6267 - accuracy: 6.9970e-04 - val_loss: 0.6260 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6266 - accuracy: 7.0083e-04 - val_loss: 0.6259 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6265 - accuracy: 7.0229e-04 - val_loss: 0.6258 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6264 - accuracy: 7.0245e-04 - val_loss: 0.6257 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6264 - accuracy: 7.0293e-04 - val_loss: 0.6256 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6263 - accuracy: 7.0390e-04 - val_loss: 0.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6262 - accuracy: 7.0471e-04 - val_loss: 0.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6262 - accuracy: 7.0487e-04 - val_loss: 0.6254 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6261 - accuracy: 7.0520e-04 - val_loss: 0.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6261 - accuracy: 7.0601e-04 - val_loss: 0.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6260 - accuracy: 7.0601e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6260 - accuracy: 7.0601e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6259 - accuracy: 7.0649e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6259 - accuracy: 7.0649e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6259 - accuracy: 7.0633e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.0746e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6258 - accuracy: 7.0649e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6258 - accuracy: 7.0746e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6257 - accuracy: 7.0746e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6257 - accuracy: 7.0795e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6257 - accuracy: 7.0762e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.0762e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6256 - accuracy: 7.0811e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6256 - accuracy: 7.0859e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6256 - accuracy: 7.0843e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6256 - accuracy: 7.0859e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6256 - accuracy: 7.0892e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.0892e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6255 - accuracy: 7.0892e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.0956e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.0924e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.0956e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1005e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.0989e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.0956e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1005e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.0989e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.0973e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1021e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.0940e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6254 - accuracy: 7.1037e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.0989e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.0989e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1070e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1070e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1037e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1037e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1037e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1102e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1102e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1264e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1183e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6253 - accuracy: 7.1134e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1167e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1134e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1134e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1134e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1167e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1231e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1231e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1199e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1183e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1280e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1231e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6252 - accuracy: 7.1264e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1264e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1312e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1280e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6252 - accuracy: 7.1264e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1296e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1409e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6252 - accuracy: 7.1377e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1409e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1361e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1409e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6253 - accuracy: 7.1312e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1361e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1506e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1377e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1361e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1458e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1409e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1393e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1442e-04 - val_loss: 0.6240 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1393e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "*** Repetición:  8\n",
      "Train on 2149 samples, validate on 380 samples\n",
      "Epoch 1/125\n",
      "2149/2149 [==============================] - 6s 3ms/sample - loss: 0.7003 - accuracy: 4.7423e-04 - val_loss: 0.6915 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6849 - accuracy: 4.8652e-04 - val_loss: 0.6781 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6738 - accuracy: 4.9380e-04 - val_loss: 0.6684 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6651 - accuracy: 5.0609e-04 - val_loss: 0.6608 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6582 - accuracy: 5.1062e-04 - val_loss: 0.6548 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6527 - accuracy: 5.1515e-04 - val_loss: 0.6502 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6487 - accuracy: 5.1580e-04 - val_loss: 0.6469 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6458 - accuracy: 5.2162e-04 - val_loss: 0.6445 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6437 - accuracy: 5.2599e-04 - val_loss: 0.6428 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6422 - accuracy: 5.3391e-04 - val_loss: 0.6414 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6410 - accuracy: 5.4200e-04 - val_loss: 0.6403 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6400 - accuracy: 5.4944e-04 - val_loss: 0.6394 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6391 - accuracy: 5.5979e-04 - val_loss: 0.6386 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6383 - accuracy: 5.7176e-04 - val_loss: 0.6378 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6375 - accuracy: 5.7920e-04 - val_loss: 0.6370 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6368 - accuracy: 5.8761e-04 - val_loss: 0.6362 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6360 - accuracy: 5.9812e-04 - val_loss: 0.6355 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6353 - accuracy: 6.0928e-04 - val_loss: 0.6348 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6346 - accuracy: 6.1365e-04 - val_loss: 0.6340 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6339 - accuracy: 6.2546e-04 - val_loss: 0.6333 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6333 - accuracy: 6.3274e-04 - val_loss: 0.6327 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6327 - accuracy: 6.4082e-04 - val_loss: 0.6321 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6321 - accuracy: 6.4875e-04 - val_loss: 0.6315 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6315 - accuracy: 6.5587e-04 - val_loss: 0.6309 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6310 - accuracy: 6.6217e-04 - val_loss: 0.6304 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6305 - accuracy: 6.6670e-04 - val_loss: 0.6299 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6301 - accuracy: 6.7075e-04 - val_loss: 0.6295 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6297 - accuracy: 6.7624e-04 - val_loss: 0.6291 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6293 - accuracy: 6.7996e-04 - val_loss: 0.6287 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6290 - accuracy: 6.8255e-04 - val_loss: 0.6284 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6287 - accuracy: 6.8579e-04 - val_loss: 0.6280 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6284 - accuracy: 6.8838e-04 - val_loss: 0.6278 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6282 - accuracy: 6.9048e-04 - val_loss: 0.6275 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6279 - accuracy: 6.9274e-04 - val_loss: 0.6273 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6277 - accuracy: 6.9468e-04 - val_loss: 0.6270 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6275 - accuracy: 6.9582e-04 - val_loss: 0.6269 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6273 - accuracy: 6.9695e-04 - val_loss: 0.6267 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6272 - accuracy: 6.9889e-04 - val_loss: 0.6265 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6270 - accuracy: 6.9937e-04 - val_loss: 0.6264 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6269 - accuracy: 6.9937e-04 - val_loss: 0.6262 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6268 - accuracy: 7.0131e-04 - val_loss: 0.6261 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6267 - accuracy: 7.0261e-04 - val_loss: 0.6260 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6266 - accuracy: 7.0326e-04 - val_loss: 0.6259 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6265 - accuracy: 7.0358e-04 - val_loss: 0.6258 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6264 - accuracy: 7.0390e-04 - val_loss: 0.6257 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6263 - accuracy: 7.0584e-04 - val_loss: 0.6256 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6263 - accuracy: 7.0601e-04 - val_loss: 0.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6262 - accuracy: 7.0681e-04 - val_loss: 0.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6262 - accuracy: 7.0746e-04 - val_loss: 0.6254 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6261 - accuracy: 7.0778e-04 - val_loss: 0.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6261 - accuracy: 7.0730e-04 - val_loss: 0.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6260 - accuracy: 7.0859e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6260 - accuracy: 7.0875e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6259 - accuracy: 7.0924e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6259 - accuracy: 7.0924e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.0973e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.0973e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.1021e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.1005e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.1053e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.1053e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.1134e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6257 - accuracy: 7.1118e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1150e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1086e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1199e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1070e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1134e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.1150e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1167e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1199e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1183e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1183e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6255 - accuracy: 7.1231e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6255 - accuracy: 7.1264e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.1264e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1345e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1199e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1280e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1215e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1328e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1280e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1296e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1248e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6254 - accuracy: 7.1345e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1328e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1328e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1296e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1328e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1393e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1345e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1377e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1393e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1425e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1425e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1458e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6253 - accuracy: 7.1393e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1361e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1425e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6252 - accuracy: 7.1361e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1425e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6252 - accuracy: 7.1377e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1345e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1425e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1425e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1442e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6252 - accuracy: 7.1328e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1409e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1442e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1425e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6252 - accuracy: 7.1425e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1361e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1328e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1425e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1474e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1409e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1377e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1425e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1425e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1393e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6251 - accuracy: 7.1442e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1458e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1458e-04 - val_loss: 0.6240 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1506e-04 - val_loss: 0.6240 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1458e-04 - val_loss: 0.6240 - val_accuracy: 0.0000e+00\n",
      "*** Repetición:  9\n",
      "Train on 2149 samples, validate on 380 samples\n",
      "Epoch 1/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.7009 - accuracy: 4.6517e-04 - val_loss: 0.6907 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6846 - accuracy: 4.7310e-04 - val_loss: 0.6774 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6732 - accuracy: 4.8717e-04 - val_loss: 0.6679 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6645 - accuracy: 4.9412e-04 - val_loss: 0.6603 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6576 - accuracy: 5.0108e-04 - val_loss: 0.6543 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6523 - accuracy: 5.0480e-04 - val_loss: 0.6499 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6484 - accuracy: 5.0787e-04 - val_loss: 0.6467 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6456 - accuracy: 5.1386e-04 - val_loss: 0.6445 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6436 - accuracy: 5.2081e-04 - val_loss: 0.6428 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6422 - accuracy: 5.2712e-04 - val_loss: 0.6415 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6410 - accuracy: 5.3294e-04 - val_loss: 0.6405 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6400 - accuracy: 5.4168e-04 - val_loss: 0.6396 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6392 - accuracy: 5.5122e-04 - val_loss: 0.6387 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6384 - accuracy: 5.6011e-04 - val_loss: 0.6379 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6376 - accuracy: 5.7176e-04 - val_loss: 0.6371 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6368 - accuracy: 5.8405e-04 - val_loss: 0.6364 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6361 - accuracy: 5.9230e-04 - val_loss: 0.6356 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6353 - accuracy: 6.0346e-04 - val_loss: 0.6348 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6346 - accuracy: 6.1365e-04 - val_loss: 0.6341 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6339 - accuracy: 6.2287e-04 - val_loss: 0.6334 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6333 - accuracy: 6.3193e-04 - val_loss: 0.6327 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6327 - accuracy: 6.4098e-04 - val_loss: 0.6321 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6320 - accuracy: 6.4794e-04 - val_loss: 0.6315 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6315 - accuracy: 6.5376e-04 - val_loss: 0.6309 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6310 - accuracy: 6.6104e-04 - val_loss: 0.6304 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6305 - accuracy: 6.6411e-04 - val_loss: 0.6299 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6301 - accuracy: 6.6897e-04 - val_loss: 0.6295 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6297 - accuracy: 6.7236e-04 - val_loss: 0.6291 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6293 - accuracy: 6.7899e-04 - val_loss: 0.6287 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6289 - accuracy: 6.8126e-04 - val_loss: 0.6283 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6286 - accuracy: 6.8288e-04 - val_loss: 0.6280 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6284 - accuracy: 6.8724e-04 - val_loss: 0.6277 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6281 - accuracy: 6.8886e-04 - val_loss: 0.6275 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6279 - accuracy: 6.9064e-04 - val_loss: 0.6272 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6277 - accuracy: 6.9242e-04 - val_loss: 0.6270 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6275 - accuracy: 6.9404e-04 - val_loss: 0.6268 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6273 - accuracy: 6.9501e-04 - val_loss: 0.6266 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6272 - accuracy: 6.9727e-04 - val_loss: 0.6265 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6270 - accuracy: 6.9937e-04 - val_loss: 0.6263 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6269 - accuracy: 6.9937e-04 - val_loss: 0.6262 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6268 - accuracy: 7.0115e-04 - val_loss: 0.6261 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6267 - accuracy: 7.0115e-04 - val_loss: 0.6260 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6266 - accuracy: 7.0099e-04 - val_loss: 0.6259 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6265 - accuracy: 7.0212e-04 - val_loss: 0.6258 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6264 - accuracy: 7.0245e-04 - val_loss: 0.6257 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6263 - accuracy: 7.0471e-04 - val_loss: 0.6256 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6263 - accuracy: 7.0503e-04 - val_loss: 0.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6262 - accuracy: 7.0503e-04 - val_loss: 0.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6261 - accuracy: 7.0503e-04 - val_loss: 0.6254 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6261 - accuracy: 7.0649e-04 - val_loss: 0.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6260 - accuracy: 7.0601e-04 - val_loss: 0.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6260 - accuracy: 7.0633e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6259 - accuracy: 7.0617e-04 - val_loss: 0.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6259 - accuracy: 7.0698e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6259 - accuracy: 7.0730e-04 - val_loss: 0.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.0795e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.0778e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6258 - accuracy: 7.0746e-04 - val_loss: 0.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6257 - accuracy: 7.0795e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.0795e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.0892e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6257 - accuracy: 7.0762e-04 - val_loss: 0.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6257 - accuracy: 7.0811e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6256 - accuracy: 7.0827e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.0827e-04 - val_loss: 0.6248 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6256 - accuracy: 7.0811e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6256 - accuracy: 7.0892e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6256 - accuracy: 7.0908e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6255 - accuracy: 7.0989e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6255 - accuracy: 7.0940e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6255 - accuracy: 7.0956e-04 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6255 - accuracy: 7.0908e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6255 - accuracy: 7.0973e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6255 - accuracy: 7.0973e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6255 - accuracy: 7.1070e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1021e-04 - val_loss: 0.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6254 - accuracy: 7.1118e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1070e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1053e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1053e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1070e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1070e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1037e-04 - val_loss: 0.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6254 - accuracy: 7.1053e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/125\n",
      "2149/2149 [==============================] - 3s 1ms/sample - loss: 0.6254 - accuracy: 7.1053e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1037e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6253 - accuracy: 7.1070e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1070e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1118e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1102e-04 - val_loss: 0.6244 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1134e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1053e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1134e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6253 - accuracy: 7.1086e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1167e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1118e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1199e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1199e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1102e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6253 - accuracy: 7.1102e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1231e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1183e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1215e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1280e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1248e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1345e-04 - val_loss: 0.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1231e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1312e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1264e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1215e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1248e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1248e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1328e-04 - val_loss: 0.6242 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6252 - accuracy: 7.1231e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/125\n",
      "2149/2149 [==============================] - 3s 2ms/sample - loss: 0.6252 - accuracy: 7.1328e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1280e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1199e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1215e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1248e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6252 - accuracy: 7.1183e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1264e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1296e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/125\n",
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1296e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149/2149 [==============================] - 5s 2ms/sample - loss: 0.6251 - accuracy: 7.1280e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/125\n",
      "2149/2149 [==============================] - 4s 2ms/sample - loss: 0.6251 - accuracy: 7.1248e-04 - val_loss: 0.6241 - val_accuracy: 0.0000e+00\n",
      "\n",
      " --- mse final: [0.0034111  0.00325158 0.00338689 0.00322353]\n"
     ]
    }
   ],
   "source": [
    "repeticiones = 10\n",
    "mse = []\n",
    "for i in range(repeticiones):\n",
    "    print(\"*** Repetición: \", i)\n",
    "    encoder_model, autoencoder_model = autoencoder.autoencoder_stacked(entrada=espectros_train_scaled,\n",
    "                                                  train_set=espectros_train_scaled,\n",
    "                                                  test_set=espectros_test_scaled)\n",
    "    espectros_latentes = encoder_model.predict(espectros_scaled)\n",
    "    espectros_salida = autoencoder_model.predict(espectros_scaled)\n",
    "    mse_cuartos = []\n",
    "    for n in range(4):\n",
    "        num_elems_cuarto = int(len(espectros_scaled) / 4)\n",
    "        mse_cuartos.append(np.mean(np.mean(np.power(espectros_scaled[(n*num_elems_cuarto):((n+1)*num_elems_cuarto)] -\n",
    "                                            espectros_salida[(n*num_elems_cuarto):((n+1)*num_elems_cuarto)], 2),\n",
    "                                   axis=0), axis=0)) \n",
    "    mse.append(mse_cuartos)\n",
    "mse_final = np.mean(mse, axis=0)\n",
    "print()\n",
    "print(\" --- mse final:\", mse_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según estos resultados, no parece que haya diferencias notables entre los 4 cuartos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a repetir 25 veces el proceso de entrenar el autoencoder, generar los outliers con el procedimiento de máximo error mse y con el procedimiento con DBSCAN.\n",
    "\n",
    "Después analizaremos cuantas veces se repiten los outliers en esas repeticiones por cada método y cuantos outliers se repiten en ambos métodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-06T18:59:19.430213Z",
     "start_time": "2019-10-06T18:56:27.942208Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1006 19:56:27.999499 140622982924096 deprecation_wrapper.py:119] From /home/joselquin/anaconda3/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1006 19:56:28.000963 140622982924096 deprecation_wrapper.py:119] From /home/joselquin/anaconda3/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1006 19:56:28.003786 140622982924096 deprecation_wrapper.py:119] From /home/joselquin/anaconda3/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1006 19:56:28.023028 140622982924096 deprecation.py:323] From /home/joselquin/anaconda3/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3217: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1006 19:56:28.106870 140622982924096 deprecation_wrapper.py:119] From /home/joselquin/anaconda3/envs/python/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1006 19:56:28.112798 140622982924096 deprecation_wrapper.py:119] From /home/joselquin/anaconda3/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetición:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1006 19:56:28.463434 140622982924096 deprecation_wrapper.py:119] From /home/joselquin/anaconda3/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2149 samples, validate on 380 samples\n",
      "Epoch 1/125\n",
      "2149/2149 [==============================] - 6s 3ms/step - loss: 0.6995 - acc: 4.6388e-04 - val_loss: 0.6878 - val_acc: 0.0000e+00\n",
      "Epoch 2/125\n",
      "2149/2149 [==============================] - 3s 2ms/step - loss: 0.6829 - acc: 4.8151e-04 - val_loss: 0.6759 - val_acc: 0.0000e+00\n",
      "Epoch 3/125\n",
      "2149/2149 [==============================] - 3s 2ms/step - loss: 0.6719 - acc: 4.9364e-04 - val_loss: 0.6668 - val_acc: 0.0000e+00\n",
      "Epoch 4/125\n",
      "2149/2149 [==============================] - 3s 2ms/step - loss: 0.6636 - acc: 4.9800e-04 - val_loss: 0.6594 - val_acc: 0.0000e+00\n",
      "Epoch 5/125\n",
      "2149/2149 [==============================] - 3s 2ms/step - loss: 0.6569 - acc: 5.0334e-04 - val_loss: 0.6537 - val_acc: 0.0000e+00\n",
      "Epoch 6/125\n",
      "2149/2149 [==============================] - 3s 2ms/step - loss: 0.6518 - acc: 5.0771e-04 - val_loss: 0.6495 - val_acc: 0.0000e+00\n",
      "Epoch 7/125\n",
      "2149/2149 [==============================] - 3s 1ms/step - loss: 0.6482 - acc: 5.0933e-04 - val_loss: 0.6465 - val_acc: 0.0000e+00\n",
      "Epoch 8/125\n",
      "2149/2149 [==============================] - 3s 2ms/step - loss: 0.6455 - acc: 5.1499e-04 - val_loss: 0.6444 - val_acc: 0.0000e+00\n",
      "Epoch 9/125\n",
      "2149/2149 [==============================] - 3s 2ms/step - loss: 0.6437 - acc: 5.2275e-04 - val_loss: 0.6428 - val_acc: 0.0000e+00\n",
      "Epoch 10/125\n",
      "2149/2149 [==============================] - 3s 1ms/step - loss: 0.6423 - acc: 5.2599e-04 - val_loss: 0.6416 - val_acc: 0.0000e+00\n",
      "Epoch 11/125\n",
      "2149/2149 [==============================] - 3s 1ms/step - loss: 0.6412 - acc: 5.3246e-04 - val_loss: 0.6406 - val_acc: 0.0000e+00\n",
      "Epoch 12/125\n",
      "2149/2149 [==============================] - 3s 2ms/step - loss: 0.6403 - acc: 5.4200e-04 - val_loss: 0.6398 - val_acc: 0.0000e+00\n",
      "Epoch 13/125\n",
      "2149/2149 [==============================] - 3s 2ms/step - loss: 0.6394 - acc: 5.5219e-04 - val_loss: 0.6389 - val_acc: 0.0000e+00\n",
      "Epoch 14/125\n",
      "2149/2149 [==============================] - 4s 2ms/step - loss: 0.6387 - acc: 5.6367e-04 - val_loss: 0.6382 - val_acc: 0.0000e+00\n",
      "Epoch 15/125\n",
      "2149/2149 [==============================] - 5s 2ms/step - loss: 0.6379 - acc: 5.7386e-04 - val_loss: 0.6374 - val_acc: 0.0000e+00\n",
      "Epoch 16/125\n",
      "2149/2149 [==============================] - 5s 2ms/step - loss: 0.6372 - acc: 5.8098e-04 - val_loss: 0.6367 - val_acc: 0.0000e+00\n",
      "Epoch 17/125\n",
      "2149/2149 [==============================] - 5s 2ms/step - loss: 0.6364 - acc: 5.9165e-04 - val_loss: 0.6359 - val_acc: 0.0000e+00\n",
      "Epoch 18/125\n",
      "2149/2149 [==============================] - 5s 2ms/step - loss: 0.6357 - acc: 5.9651e-04 - val_loss: 0.6352 - val_acc: 0.0000e+00\n",
      "Epoch 19/125\n",
      "2149/2149 [==============================] - 5s 2ms/step - loss: 0.6350 - acc: 6.0686e-04 - val_loss: 0.6344 - val_acc: 0.0000e+00\n",
      "Epoch 20/125\n",
      "2149/2149 [==============================] - 5s 2ms/step - loss: 0.6343 - acc: 6.1494e-04 - val_loss: 0.6337 - val_acc: 0.0000e+00\n",
      "Epoch 21/125\n",
      "2149/2149 [==============================] - 5s 2ms/step - loss: 0.6336 - acc: 6.2497e-04 - val_loss: 0.6330 - val_acc: 0.0000e+00\n",
      "Epoch 22/125\n",
      "2149/2149 [==============================] - 5s 2ms/step - loss: 0.6330 - acc: 6.3306e-04 - val_loss: 0.6324 - val_acc: 0.0000e+00\n",
      "Epoch 23/125\n",
      "2149/2149 [==============================] - 4s 2ms/step - loss: 0.6324 - acc: 6.4406e-04 - val_loss: 0.6318 - val_acc: 0.0000e+00\n",
      "Epoch 24/125\n",
      "2149/2149 [==============================] - 4s 2ms/step - loss: 0.6318 - acc: 6.4956e-04 - val_loss: 0.6312 - val_acc: 0.0000e+00\n",
      "Epoch 25/125\n",
      "2149/2149 [==============================] - 5s 2ms/step - loss: 0.6312 - acc: 6.5457e-04 - val_loss: 0.6306 - val_acc: 0.0000e+00\n",
      "Epoch 26/125\n",
      "2149/2149 [==============================] - 5s 2ms/step - loss: 0.6307 - acc: 6.6104e-04 - val_loss: 0.6301 - val_acc: 0.0000e+00\n",
      "Epoch 27/125\n",
      "2149/2149 [==============================] - 5s 2ms/step - loss: 0.6303 - acc: 6.6525e-04 - val_loss: 0.6296 - val_acc: 0.0000e+00\n",
      "Epoch 28/125\n",
      "2149/2149 [==============================] - 5s 2ms/step - loss: 0.6298 - acc: 6.7139e-04 - val_loss: 0.6292 - val_acc: 0.0000e+00\n",
      "Epoch 29/125\n",
      "2149/2149 [==============================] - 4s 2ms/step - loss: 0.6294 - acc: 6.7560e-04 - val_loss: 0.6288 - val_acc: 0.0000e+00\n",
      "Epoch 30/125\n",
      "2149/2149 [==============================] - 4s 2ms/step - loss: 0.6291 - acc: 6.7916e-04 - val_loss: 0.6285 - val_acc: 0.0000e+00\n",
      "Epoch 31/125\n",
      "2149/2149 [==============================] - 4s 2ms/step - loss: 0.6288 - acc: 6.8174e-04 - val_loss: 0.6282 - val_acc: 0.0000e+00\n",
      "Epoch 32/125\n",
      "2149/2149 [==============================] - 4s 2ms/step - loss: 0.6285 - acc: 6.8401e-04 - val_loss: 0.6279 - val_acc: 0.0000e+00\n",
      "Epoch 33/125\n",
      "2149/2149 [==============================] - 4s 2ms/step - loss: 0.6282 - acc: 6.8692e-04 - val_loss: 0.6276 - val_acc: 0.0000e+00\n",
      "Epoch 34/125\n",
      "2149/2149 [==============================] - 4s 2ms/step - loss: 0.6280 - acc: 6.8935e-04 - val_loss: 0.6273 - val_acc: 0.0000e+00\n",
      "Epoch 35/125\n",
      "2149/2149 [==============================] - 4s 2ms/step - loss: 0.6278 - acc: 6.9177e-04 - val_loss: 0.6271 - val_acc: 0.0000e+00\n",
      "Epoch 36/125\n",
      "2149/2149 [==============================] - 4s 2ms/step - loss: 0.6276 - acc: 6.9339e-04 - val_loss: 0.6269 - val_acc: 0.0000e+00\n",
      "Epoch 37/125\n",
      "2149/2149 [==============================] - 4s 2ms/step - loss: 0.6274 - acc: 6.9598e-04 - val_loss: 0.6267 - val_acc: 0.0000e+00\n",
      "Epoch 38/125\n",
      "2149/2149 [==============================] - 4s 2ms/step - loss: 0.6272 - acc: 6.9598e-04 - val_loss: 0.6266 - val_acc: 0.0000e+00\n",
      "Epoch 39/125\n",
      "2149/2149 [==============================] - 4s 2ms/step - loss: 0.6271 - acc: 6.9759e-04 - val_loss: 0.6264 - val_acc: 0.0000e+00\n",
      "Epoch 40/125\n",
      "2149/2149 [==============================] - 5s 2ms/step - loss: 0.6269 - acc: 7.0051e-04 - val_loss: 0.6263 - val_acc: 0.0000e+00\n",
      "Epoch 41/125\n",
      "1792/2149 [========================>.....] - ETA: 0s - loss: 0.6268 - acc: 6.3426e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-31de324990db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     encoder_model, autoencoder_model = galassify_autoencoder.autoencoder(entrada=espectros_train_scaled,\n\u001b[1;32m      7\u001b[0m                                                   \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mespectros_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                                   test_set=espectros_test_scaled)\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mespectros_latentes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mespectros_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mespectros_salida\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mespectros_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/joselquin/Datos_2/ML/Galassify/galassify_autoencoder.py\u001b[0m in \u001b[0;36mautoencoder\u001b[0;34m(entrada, train_set, test_set, dim_latente, epochs, lr, grabar, cargar, archivo_encoder, archivo_autoencoder, grafica)\u001b[0m\n\u001b[1;32m     55\u001b[0m                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                              \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                              validation_data=(test_set, test_set))  \n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrafica\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mgalassify_grafica_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrafica_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder_deep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/python/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "repeticiones = 25\n",
    "outliers_mse = []\n",
    "outliers_dbscan = []\n",
    "for i in range(repeticiones):\n",
    "    print(\"Repetición: \", i)\n",
    "    encoder_model, autoencoder_model = galassify_autoencoder.autoencoder(entrada=espectros_train_scaled,\n",
    "                                                  train_set=espectros_train_scaled,\n",
    "                                                  test_set=espectros_test_scaled)\n",
    "    espectros_latentes = encoder_model.predict(espectros_scaled)\n",
    "    espectros_salida = autoencoder_model.predict(espectros_scaled)\n",
    "\n",
    "    # Outliers metodo 1\n",
    "    mse = np.mean(np.power(espectros_scaled - espectros_salida, 2), axis=1)\n",
    "    df_error = pd.DataFrame({'error': mse}, index=espectros_scaled.index)\n",
    "    print(df_error.index[df_error[\"error\"] > 0.02].tolist())\n",
    "    outliers_mse.append(df_error.index[df_error[\"error\"] > 0.02].tolist())\n",
    "    \n",
    "    # Outliers método 2\n",
    "    clustering = DBSCAN(eps=3.5, min_samples=2, n_jobs=-1).fit(espectros_latentes)\n",
    "    labels_DBSCAN = np.unique(clustering.labels_, return_counts=True)\n",
    "    clusters_DBSCAN = []\n",
    "    for i in range(-1,len(labels_DBSCAN[0]), 1): # Empezamos en -1 para coger los outliers, en el índice 0 del array labels\n",
    "        clusters_DBSCAN.append(np.where(clustering.labels_==i))\n",
    "    print(clusters_DBSCAN[0][0].tolist())\n",
    "    outliers_dbscan.append(clusters_DBSCAN[0][0].tolist())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T10:10:19.165770Z",
     "start_time": "2019-08-30T10:10:19.149817Z"
    }
   },
   "outputs": [],
   "source": [
    "def porcentaje_coincidencia(listas):\n",
    "    union = []\n",
    "    for i in range(len(listas)):\n",
    "        union = set(union) | set(listas[i])\n",
    "    union = list(union)\n",
    "    repeticion = np.zeros(len(union), dtype=int)\n",
    "    for ind, item in enumerate(union):\n",
    "        for i in range(len(listas)):\n",
    "            if item in listas[i]:\n",
    "                repeticion[ind] += 1\n",
    "    return repeticion, union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-30T10:10:32.113892Z",
     "start_time": "2019-08-30T10:10:32.108135Z"
    }
   },
   "outputs": [],
   "source": [
    "r_mse, u_mse = porcentaje_coincidencia(outliers_mse)\n",
    "r_dbscan, u_dbscan = porcentaje_coincidencia(outliers_dbscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "575px",
    "left": "1453px",
    "right": "20px",
    "top": "192px",
    "width": "451px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
